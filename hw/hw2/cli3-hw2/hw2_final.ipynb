{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "hw2_final.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "W_z-mZwfjBF6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "import librosa\n",
        "import math\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0_CzvuOfjBF-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Helper functions"
      ]
    },
    {
      "metadata": {
        "id": "x9XdoynUjLb8",
        "colab_type": "code",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "outputId": "3dd2233c-d2d1-4aa0-d4a1-8dcad4f81e5f"
      },
      "cell_type": "code",
      "source": [
        "# In Google Colaborary\n",
        "from google.colab import files\n",
        "train_clean_male_wav = files.upload() # train_clean_male.wav\n",
        "train_dirty_male_wav = files.upload() # train_clean_male.wav\n",
        "\n",
        "\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-30b00cf9-23be-4178-be6c-8cf3f9d41014\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-30b00cf9-23be-4178-be6c-8cf3f9d41014\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving train_clean_male.wav to train_clean_male.wav\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-381ac58d-c5c2-45ec-af34-982f6c55b0f2\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-381ac58d-c5c2-45ec-af34-982f6c55b0f2\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving train_dirty_male.wav to train_dirty_male.wav\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "XGKPFDIej7qM",
        "colab_type": "code",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "outputId": "d74dd96d-9452-418f-c8fb-0bdfd52b03cf"
      },
      "cell_type": "code",
      "source": [
        "# In Google Colaborary\n",
        "from google.colab import files\n",
        "test_x_01 = files.upload() # train_clean_male.wav\n",
        "test_x_02 = files.upload() # train_clean_male.wav\n",
        "\n",
        "\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-7f539b5c-2d3f-4851-85f8-3321019e9732\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-7f539b5c-2d3f-4851-85f8-3321019e9732\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving test_x_01.wav to test_x_01.wav\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-60fe4678-567f-47ff-a5cb-4560f3df0bc2\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-60fe4678-567f-47ff-a5cb-4560f3df0bc2\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving test_x_02.wav to test_x_02.wav\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "UZRy8faKjBF_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Calculate SNR \n",
        "def calculateSNR(st, st_h):\n",
        "    st_sum = np.sum(np.abs(st))\n",
        "    diff_sum = np.sum(np.abs(st-st_h))\n",
        "    return 10*math.log(st_sum**2/diff_sum**2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2RLst0XKjBGB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "4a5ed2de-aa1f-429a-f551-3aab5baba580"
      },
      "cell_type": "code",
      "source": [
        "# Read training data\n",
        "s, sr_s=librosa.load('train_clean_male.wav', sr=None)\n",
        "S=librosa.stft(s, n_fft=1024, hop_length=512)\n",
        "sn, sr_x=librosa.load('train_dirty_male.wav', sr=None)\n",
        "X=librosa.stft(sn, n_fft=1024, hop_length=512)\n",
        "print(S.shape)\n",
        "print(X.shape)\n",
        "S_abs = np.abs(S)\n",
        "X_abs = np.abs(X)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(513, 2459)\n",
            "(513, 2459)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "JXsz17yqjBGF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "is_training = True\n",
        "def get_cnn1_model():\n",
        "    x = tf.placeholder(tf.float32, [None, 513, 1])\n",
        "    y_ = tf.placeholder(tf.float32, [None, 513])\n",
        "    LEARNING_RATE = 10e-4\n",
        "    BATCH_SIZE = 32\n",
        "    \n",
        "    initializer = tf.contrib.layers.variance_scaling_initializer()\n",
        "\n",
        "    conv1 = tf.layers.conv1d(\n",
        "        x,            \n",
        "        filters=32,\n",
        "        kernel_size=3,\n",
        "        activation=tf.nn.relu)\n",
        "\n",
        "    conv2 = tf.layers.conv1d(\n",
        "        conv1,            \n",
        "        filters=64,\n",
        "        kernel_size=3,\n",
        "        activation=tf.nn.relu)\n",
        "\n",
        "    conv3 = tf.layers.conv1d(\n",
        "        conv2,            \n",
        "        filters=128,\n",
        "        kernel_size=3,\n",
        "        activation=tf.nn.relu)\n",
        "\n",
        "    flat = tf.reshape(conv3, [-1, 128*507])\n",
        "    ln1 = tf.contrib.layers.layer_norm(flat)\n",
        "    l2 = tf.layers.dense(ln1, units=1024,  activation=tf.nn.relu, kernel_initializer=initializer)\n",
        "    dropout1 = tf.layers.dropout(l2, rate=0.2, training=is_training)\n",
        "    ln2 = tf.contrib.layers.layer_norm(dropout1)\n",
        "    l3 = tf.layers.dense(ln2, units=1024,  activation=tf.nn.relu, kernel_initializer=initializer)\n",
        "    dropout2 = tf.layers.dropout(l3, rate=0.2, training=is_training)\n",
        "    y = tf.layers.dense(dropout2, units=513, activation=tf.nn.relu, kernel_initializer=initializer)\n",
        "\n",
        "    loss = tf.losses.mean_squared_error(labels=y_, predictions=y)\n",
        "    train_step = tf.train.AdamOptimizer(LEARNING_RATE).minimize(loss)\n",
        "\n",
        "    sess=tf.Session()\n",
        "    tf.global_variables_initializer().run(session=sess)\n",
        "\n",
        "    train_data = tf.data.Dataset.from_tensor_slices(tf.constant(X_abs.T.reshape(-1, 513, 1)))\n",
        "    label_data = tf.data.Dataset.from_tensor_slices(tf.constant(S_abs.T))\n",
        "    batch_data = tf.data.Dataset.zip((train_data, label_data)).repeat().batch(BATCH_SIZE)\n",
        "\n",
        "    iterator = batch_data.make_one_shot_iterator()\n",
        "    next_batch = iterator.get_next()\n",
        "    return (x, y_, y, sess, next_batch, train_step, loss)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lD96IQcqjBGI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493
        },
        "outputId": "f5c91648-5acd-4138-c582-6ea52689bcf5"
      },
      "cell_type": "code",
      "source": [
        "(x1, y_1, y1, sess_1, next_batch_1, train_step_1, loss_1) = get_cnn1_model()\n",
        "\n",
        "saver = tf.train.Saver()\n",
        "\n",
        "TRAIN_STEPS = 10000\n",
        "\n",
        "\n",
        "for i in range(TRAIN_STEPS+1):    \n",
        "    batch = sess_1.run(next_batch_1)\n",
        "    _, loss_value = sess_1.run((train_step_1, loss_1), feed_dict={x1: batch[0], y_1: batch[1]})\n",
        "    if i% 500 == 0:\n",
        "        print('Training Step:' + str(i) + '  Loss =  ' + str(loss_value))\n",
        "        "
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "Training Step:0  Loss =  1.34463\n",
            "Training Step:500  Loss =  0.028354645\n",
            "Training Step:1000  Loss =  0.04534659\n",
            "Training Step:1500  Loss =  0.0008305101\n",
            "Training Step:2000  Loss =  0.020449989\n",
            "Training Step:2500  Loss =  0.03604931\n",
            "Training Step:3000  Loss =  0.016032385\n",
            "Training Step:3500  Loss =  0.029099604\n",
            "Training Step:4000  Loss =  0.012278512\n",
            "Training Step:4500  Loss =  0.017634071\n",
            "Training Step:5000  Loss =  0.0061632036\n",
            "Training Step:5500  Loss =  0.067448474\n",
            "Training Step:6000  Loss =  0.015156337\n",
            "Training Step:6500  Loss =  0.017445985\n",
            "Training Step:7000  Loss =  0.005189274\n",
            "Training Step:7500  Loss =  0.016518248\n",
            "Training Step:8000  Loss =  0.008710186\n",
            "Training Step:8500  Loss =  0.003125579\n",
            "Training Step:9000  Loss =  0.0052581294\n",
            "Training Step:9500  Loss =  0.005329778\n",
            "Training Step:10000  Loss =  0.010168812\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "-f6w9YmJkH_J",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "26bc3d04-0c1c-4db2-9740-58c4b2a85d52"
      },
      "cell_type": "code",
      "source": [
        "# Calculate SNR by training data\n",
        "is_training = False\n",
        "S_test_abs = sess_1.run(y1, feed_dict={x1: X_abs.T.reshape(-1, 513, 1) }).T\n",
        "is_training = True\n",
        "ratio = (X / X_abs)\n",
        "s_t = np.multiply(ratio, S_test_abs)\n",
        "print(calculateSNR(S, s_t))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "15.089389977662648\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "C0NTbiBvjBGL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def denoise_sound_conv1(sess, x, y, input_file_name, output_file_name):\n",
        "    sn, sr=librosa.load(input_file_name, sr=None)\n",
        "    testX=librosa.stft(sn, n_fft=1024, hop_length=512)\n",
        "    testX_abs = np.abs(testX)\n",
        "    is_training = False\n",
        "    S_test_abs = sess.run(y, feed_dict={x: testX_abs.T.reshape(-1, 513, 1) }).T\n",
        "    is_training = True\n",
        "    print(S_test_abs.shape)\n",
        "    ratio = (testX / testX_abs)\n",
        "    Sh = np.multiply(ratio, S_test_abs)\n",
        "    librosa.output.write_wav(output_file_name, librosa.istft(Sh, hop_length=512), sr)\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hgU_tzBpjBGN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "cc3f3a3a-da20-412b-df5c-f7ecbc15a5ff"
      },
      "cell_type": "code",
      "source": [
        "denoise_sound_conv1(sess_1, x1, y1, 'test_x_01.wav', 'recover_01_d1x.wav')\n",
        "denoise_sound_conv1(sess_1, x1, y1, 'test_x_02.wav', 'recover_02_d1x.wav')"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(513, 142)\n",
            "(513, 380)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "JlrkFpl5lWaM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "files.download('recover_01_d1x.wav')\n",
        "files.download('recover_02_d1x.wav')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-nvqEMmvjBGT",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### CNN 2D\n"
      ]
    },
    {
      "metadata": {
        "id": "w-11AYvbjBGT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Transform a spectra to image like data form with dim 20x513\n",
        "def imageize_spec(X):\n",
        "    raw = []\n",
        "    for t in range(len(X)-19):\n",
        "        raw.append(X[t: t+20])\n",
        "    X_abs_2d = np.array(raw).reshape(-1, 20, 513, 1)\n",
        "    return X_abs_2d    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "T46CaoWhjBGV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Padding \n",
        "def padding_frames(X):\n",
        "    testX_pad = X\n",
        "    # padding\n",
        "    for i in range(19):\n",
        "        testX_pad = np.hstack((testX_pad, np.zeros((513, 1))))\n",
        "    return testX_pad\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gRneV_mOjBGY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e118c5c6-aa1b-4324-be5c-25d6e4ad1e36"
      },
      "cell_type": "code",
      "source": [
        "# \"imageize\" data for 2D CNN, before that we will pad 19 empty frame at the end\n",
        "X_abs_T = np.abs(padding_frames(X)).T\n",
        "X_abs_2d = imageize_spec(X_abs_T)\n",
        "\n",
        "print(X_abs_2d.shape)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(2459, 20, 513, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "LInxLcBQjBGb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "is_training = True\n",
        "def get_cnn2_model():\n",
        "    x = tf.placeholder(tf.float32, [None, 20, 513, 1])\n",
        "    y_ = tf.placeholder(tf.float32, [None, 513])\n",
        "    LEARNING_RATE = 10e-5\n",
        "    BATCH_SIZE = 64\n",
        "    \n",
        "    initializer = tf.contrib.layers.variance_scaling_initializer()\n",
        "\n",
        "    #  18 * 511 * 16 \n",
        "    conv1 = tf.layers.conv2d(\n",
        "        x,            \n",
        "        filters=16,\n",
        "        kernel_size=[3, 3],\n",
        "        activation=tf.nn.relu)\n",
        "\n",
        "    # 9 * 255 * 16\n",
        "    pool1 = tf.layers.max_pooling2d(inputs=conv1, pool_size=[2, 2], strides=2)\n",
        "\n",
        "    # 7 * 253 * 32\n",
        "    conv2 = tf.layers.conv2d(\n",
        "        pool1,            \n",
        "        filters=64,\n",
        "        kernel_size=[3, 3],\n",
        "        activation=tf.nn.relu)\n",
        "\n",
        "    # 3 * 126 * 32\n",
        "    pool2 = tf.layers.max_pooling2d(inputs=conv2, pool_size=[2, 2], strides=2)\n",
        "\n",
        "    # 1 * 124 * 64\n",
        "    conv3 = tf.layers.conv2d(\n",
        "        pool2,            \n",
        "        filters=64,\n",
        "        kernel_size=[3, 3],\n",
        "        activation=tf.nn.relu)\n",
        "\n",
        "    flat = tf.reshape(conv3, [-1, 124*64])\n",
        "    \n",
        "    ln1 = tf.contrib.layers.layer_norm(flat)\n",
        "    l2 = tf.layers.dense(ln1, units=1024,  activation=tf.nn.relu, kernel_initializer=initializer)\n",
        "    dropout1 = tf.layers.dropout(l2, rate=0.2, training=is_training)\n",
        "    ln2 = tf.contrib.layers.layer_norm(dropout1)\n",
        "    l3 = tf.layers.dense(ln2, units=1024,  activation=tf.nn.relu, kernel_initializer=initializer)\n",
        "    dropout2 = tf.layers.dropout(l3, rate=0.2, training=is_training)\n",
        "    y = tf.layers.dense(dropout2, units=513, activation=tf.nn.relu, kernel_initializer=initializer)\n",
        "\n",
        "    loss = tf.losses.mean_squared_error(labels=y_, predictions=y)\n",
        "    train_step = tf.train.AdamOptimizer(LEARNING_RATE).minimize(loss)\n",
        "\n",
        "    sess=tf.Session()\n",
        "    tf.global_variables_initializer().run(session=sess)\n",
        "    \n",
        "    # Modify data for training\n",
        "    train_data = tf.data.Dataset.from_tensor_slices(tf.constant(X_abs_2d))\n",
        "    label_data = tf.data.Dataset.from_tensor_slices(tf.constant(S_abs.T))\n",
        "    batch_data = tf.data.Dataset.zip((train_data, label_data)).repeat().batch(BATCH_SIZE)\n",
        "\n",
        "    iterator = batch_data.make_one_shot_iterator()\n",
        "    next_batch = iterator.get_next()\n",
        "\n",
        "    return (x, y_, y, sess, next_batch, train_step, loss)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ehExrXo3jBGe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 544
        },
        "outputId": "1a02584e-c518-4af0-ee83-2326980ddd01"
      },
      "cell_type": "code",
      "source": [
        "(x2, y_2, y2, sess_2, next_batch_2, train_step_2, loss_2) = get_cnn2_model()\n",
        "\n",
        "TRAIN_STEPS = 15000\n",
        "\n",
        "for i in range(TRAIN_STEPS+1):    \n",
        "    batch = sess_2.run(next_batch_2)\n",
        "    _, loss_value = sess_2.run((train_step_2, loss_2), feed_dict={x2: batch[0], y_2: batch[1]})\n",
        "    if i% 500 == 0:\n",
        "        print('Training Step:' + str(i) + '  Loss =  ' + str(loss_value))\n"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training Step:0  Loss =  1.2867198\n",
            "Training Step:500  Loss =  0.0798838\n",
            "Training Step:1000  Loss =  0.035159424\n",
            "Training Step:1500  Loss =  0.025857322\n",
            "Training Step:2000  Loss =  0.014877802\n",
            "Training Step:2500  Loss =  0.016420899\n",
            "Training Step:3000  Loss =  0.014716226\n",
            "Training Step:3500  Loss =  0.013950449\n",
            "Training Step:4000  Loss =  0.013395712\n",
            "Training Step:4500  Loss =  0.01250609\n",
            "Training Step:5000  Loss =  0.01670644\n",
            "Training Step:5500  Loss =  0.011480769\n",
            "Training Step:6000  Loss =  0.0070692473\n",
            "Training Step:6500  Loss =  0.008225092\n",
            "Training Step:7000  Loss =  0.0051851915\n",
            "Training Step:7500  Loss =  0.00489032\n",
            "Training Step:8000  Loss =  0.0042150742\n",
            "Training Step:8500  Loss =  0.0019531136\n",
            "Training Step:9000  Loss =  0.0057302997\n",
            "Training Step:9500  Loss =  0.009187471\n",
            "Training Step:10000  Loss =  0.008794038\n",
            "Training Step:10500  Loss =  0.012084844\n",
            "Training Step:11000  Loss =  0.0075779054\n",
            "Training Step:11500  Loss =  0.004853153\n",
            "Training Step:12000  Loss =  0.004122775\n",
            "Training Step:12500  Loss =  0.008277785\n",
            "Training Step:13000  Loss =  0.013189156\n",
            "Training Step:13500  Loss =  0.011026613\n",
            "Training Step:14000  Loss =  0.0054138144\n",
            "Training Step:14500  Loss =  0.0060614813\n",
            "Training Step:15000  Loss =  0.0043995674\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "pFV1osEe8d6e",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6c8dfa60-048b-42b3-a9a0-5d28d573ea2b"
      },
      "cell_type": "code",
      "source": [
        "# Calculate SNR by training data\n",
        "\n",
        "X_abs_T = np.abs(padding_frames(X)).T\n",
        "X_abs_2d = imageize_spec(X_abs_T)\n",
        "\n",
        "is_training = False\n",
        "S_test_abs = sess_2.run(y2, feed_dict={x2: X_abs_2d }).T\n",
        "is_training = True\n",
        "\n",
        "ratio = (X / X_abs)\n",
        "s_t = np.multiply(ratio, S_test_abs)\n",
        "print(calculateSNR(S, s_t))\n"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "13.836223441561268\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "MFMwPMQAjBGi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def denoise_sound_conv2(sess, x, y, input_file_name, output_file_name):\n",
        "    sn, sr=librosa.load(input_file_name, sr=None)\n",
        "    testX=librosa.stft(sn, n_fft=1024, hop_length=512)\n",
        "    testX_abs = np.abs(testX)\n",
        "    testX_abs_pad = np.abs(padding_frames(testX))\n",
        "    X_abs_2d = imageize_spec(testX_abs_pad.T)\n",
        "    is_training = False\n",
        "    S_test_abs = sess.run(y, feed_dict={x: X_abs_2d }).T\n",
        "    is_training = True\n",
        "    print(S_test_abs.shape)\n",
        "    ratio = (testX / testX_abs)\n",
        "    Sh = np.multiply(ratio, S_test_abs)\n",
        "    librosa.output.write_wav(output_file_name, librosa.istft(Sh, hop_length=512), sr)\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bfvKTdI3jBGk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "faf976cb-ea5f-4ef1-e649-53d1892f31ed"
      },
      "cell_type": "code",
      "source": [
        "denoise_sound_conv2(sess_2, x2, y2, 'test_x_01.wav', 'recover_01_d2x.wav')\n",
        "denoise_sound_conv2(sess_2, x2, y2, 'test_x_02.wav', 'recover_02_d2x.wav')"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(513, 142)\n",
            "(513, 380)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "d0XUlICljBGn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "files.download('recover_01_d2x.wav')\n",
        "files.download('recover_02_d2x.wav')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xCaGu0imjBGr",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Result\n",
        "\n",
        "I found the training time of 1D CNN is much faster than 2D CNN, since the parameters to train is much smaller in 1D CNN model.\n",
        "\n",
        "For SNR for the training data, 1D CNN model can reached 15dB, and 2D CNN can also reach 1dB.\n",
        "\n",
        "However, even the SNR of 2D CNN can be as good as the 1D CNN, I still feel the quality of 1D CNN is much better than 2D CNN based on my subjective listening test."
      ]
    },
    {
      "metadata": {
        "id": "BS-ySlcrjBGt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}