{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, Conv1D, Conv2D, Flatten, Dropout, MaxPooling2D, BatchNormalization\n",
    "\n",
    "import librosa\n",
    "import math\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform a spectra to image like data form with dim 20x513\n",
    "def imageize_spec(X):\n",
    "    raw = []\n",
    "    for t in range(len(X)-19):\n",
    "        raw.append(X[t: t+20])\n",
    "    X_abs_2d = np.array(raw).reshape(-1, 20, 513, 1)\n",
    "    return X_abs_2d\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate SNR \n",
    "def calculateSNR(st, st_h):\n",
    "    st_sum = np.sum(np.abs(st))\n",
    "    diff_sum = np.sum(np.abs(st-st_h))\n",
    "#     print(st_sum, diff_sum)\n",
    "    return 10*math.log(st_sum**2/diff_sum**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(513, 2459)\n",
      "(513, 2459)\n"
     ]
    }
   ],
   "source": [
    "# Load training data \n",
    "s, sr_s=librosa.load('data/train_clean_male.wav', sr=None)\n",
    "S=librosa.stft(s, n_fft=1024, hop_length=512)\n",
    "sn, sr_x=librosa.load('data/train_dirty_male.wav', sr=None)\n",
    "X=librosa.stft(sn, n_fft=1024, hop_length=512)\n",
    "print(S.shape)\n",
    "print(X.shape)\n",
    "S_abs = np.abs(S)\n",
    "X_abs = np.abs(X)\n",
    "\n",
    "X_train = X_abs.T[:].reshape(-1, 513, 1)\n",
    "y_train = S_abs.T[:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://towardsdatascience.com/building-a-convolutional-neural-network-cnn-in-keras-329fbbadc5f5\n",
    "model_path = './keras_1.h5'\n",
    "\n",
    "#create model\n",
    "model1 = Sequential()\n",
    "\n",
    "try:\n",
    "    model1 = load_model(model_path)\n",
    "except:\n",
    "    #add model layers\n",
    "    model1.add(Conv1D(128, kernel_size=3, activation='relu', input_shape=(513,1)))\n",
    "    model1.add(Conv1D(64, kernel_size=3, activation='relu'))\n",
    "    model1.add(Conv1D(32, kernel_size=3, activation='relu'))\n",
    "    model1.add(Flatten())\n",
    "    model1.add(BatchNormalization())\n",
    "    model1.add(Dense(512, activation='relu'))\n",
    "    model1.add(BatchNormalization())\n",
    "    model1.add(Dropout(0.2))    \n",
    "    model1.add(Dense(512, activation='relu'))\n",
    "    model1.add(Dropout(0.2))\n",
    "    model1.add(Dense(513, activation='relu'))\n",
    "\n",
    "    #compile model using accuracy to measure model performance\n",
    "    model1.compile(optimizer='adam', loss='mean_squared_error', metrics=['accuracy'])\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "2459/2459 [==============================] - 10s 4ms/step - loss: 0.0203 - acc: 0.3778\n",
      "Epoch 2/10\n",
      "2459/2459 [==============================] - 10s 4ms/step - loss: 0.0203 - acc: 0.3611\n",
      "Epoch 3/10\n",
      "2459/2459 [==============================] - 10s 4ms/step - loss: 0.0196 - acc: 0.3721\n",
      "Epoch 4/10\n",
      "2459/2459 [==============================] - 11s 4ms/step - loss: 0.0190 - acc: 0.3693\n",
      "Epoch 5/10\n",
      "2459/2459 [==============================] - 11s 4ms/step - loss: 0.0183 - acc: 0.3770\n",
      "Epoch 6/10\n",
      "2459/2459 [==============================] - 12s 5ms/step - loss: 0.0179 - acc: 0.3737\n",
      "Epoch 7/10\n",
      "2459/2459 [==============================] - 11s 4ms/step - loss: 0.0174 - acc: 0.3754\n",
      "Epoch 8/10\n",
      "2459/2459 [==============================] - 11s 4ms/step - loss: 0.0192 - acc: 0.3729\n",
      "Epoch 9/10\n",
      "2459/2459 [==============================] - 11s 4ms/step - loss: 0.0177 - acc: 0.3648\n",
      "Epoch 10/10\n",
      "2459/2459 [==============================] - 11s 4ms/step - loss: 0.0172 - acc: 0.3701\n"
     ]
    }
   ],
   "source": [
    "model1.fit(X_train, y_train, epochs=10)\n",
    "model1.save(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def denoise_sound_conv1(input_file_name, output_file_name):\n",
    "    sn, sr=librosa.load(input_file_name, sr=None)\n",
    "    testX=librosa.stft(sn, n_fft=1024, hop_length=512)\n",
    "    testX_abs = np.abs(testX)\n",
    "    S_test_abs = model1.predict(testX_abs.T.reshape(-1, 513, 1)).T.reshape(513, -1)\n",
    "    ratio = (testX / testX_abs)\n",
    "    Sh = np.multiply(ratio, S_test_abs)\n",
    "    librosa.output.write_wav(output_file_name, librosa.istft(Sh, hop_length=512), sr)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "denoise_sound_conv1('data/test_x_01.wav', 'recover_01_d1.wav')\n",
    "denoise_sound_conv1('data/test_x_02.wav', 'recover_02_d1.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.221322455695503\n"
     ]
    }
   ],
   "source": [
    "# Calculate SNR by training data\n",
    "S_test_abs = model1.predict(X_train).T.reshape(513, -1)\n",
    "ratio = (X / X_abs)\n",
    "s_t = np.multiply(ratio, S_test_abs)\n",
    "print(calculateSNR(S, s_t))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2D CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def padding_frames(X):\n",
    "    testX_pad = X\n",
    "    # padding\n",
    "    for i in range(19):\n",
    "        testX_pad = np.hstack((testX_pad, np.zeros((513, 1))))\n",
    "    return testX_pad\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2459, 20, 513, 1)\n",
      "(2459, 513)\n"
     ]
    }
   ],
   "source": [
    "# \"imageize\" data for 2D CNN\n",
    "S_abs_T = S_abs.T\n",
    "X_abs_T = np.abs(padding_frames(X)).T\n",
    "S_abs_2d = S_abs_T\n",
    "X_abs_2d = imageize_spec(X_abs_T)\n",
    "\n",
    "print(X_abs_2d.shape)\n",
    "print(S_abs_T.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = './keras_2.h5'\n",
    "\n",
    "#create model\n",
    "model2 = Sequential()\n",
    "\n",
    "try:\n",
    "    model2 = load_model(model_path)\n",
    "except:\n",
    "    #add model layers\n",
    "    model2.add(Conv2D(16, (3, 3), activation='relu', input_shape=(20, 513,1)))\n",
    "    model2.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "    model2.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model2.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "    model2.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    model2.add(Flatten())\n",
    "    model2.add(BatchNormalization())\n",
    "    model2.add(Dense(512, activation='relu'))\n",
    "    model2.add(BatchNormalization())\n",
    "    model2.add(Dense(512, activation='relu'))\n",
    "    model2.add(Dropout(0.2))\n",
    "    model2.add(Dense(513, activation='relu'))\n",
    "\n",
    "    #compile model using accuracy to measure model performance\n",
    "    model2.compile(optimizer='adam', loss='mean_squared_error', metrics=['accuracy'])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "2459/2459 [==============================] - 63s 26ms/step - loss: 0.1044 - acc: 0.0256\n",
      "Epoch 2/20\n",
      "2459/2459 [==============================] - 62s 25ms/step - loss: 0.0812 - acc: 0.0484\n",
      "Epoch 3/20\n",
      "2459/2459 [==============================] - 61s 25ms/step - loss: 0.0637 - acc: 0.1273\n",
      "Epoch 4/20\n",
      "2459/2459 [==============================] - 62s 25ms/step - loss: 0.0489 - acc: 0.1736\n",
      "Epoch 5/20\n",
      "2459/2459 [==============================] - 62s 25ms/step - loss: 0.0425 - acc: 0.2102\n",
      "Epoch 6/20\n",
      "2459/2459 [==============================] - 62s 25ms/step - loss: 0.0362 - acc: 0.2517\n",
      "Epoch 7/20\n",
      "2459/2459 [==============================] - 62s 25ms/step - loss: 0.0327 - acc: 0.2745\n",
      "Epoch 8/20\n",
      "2459/2459 [==============================] - 62s 25ms/step - loss: 0.0301 - acc: 0.3026\n",
      "Epoch 9/20\n",
      "2459/2459 [==============================] - 62s 25ms/step - loss: 0.0280 - acc: 0.3131\n",
      "Epoch 10/20\n",
      "2459/2459 [==============================] - 62s 25ms/step - loss: 0.0269 - acc: 0.3156\n",
      "Epoch 11/20\n",
      "2459/2459 [==============================] - 64s 26ms/step - loss: 0.0242 - acc: 0.3290\n",
      "Epoch 12/20\n",
      "2459/2459 [==============================] - 67s 27ms/step - loss: 0.0230 - acc: 0.3355\n",
      "Epoch 13/20\n",
      "2459/2459 [==============================] - 64s 26ms/step - loss: 0.0220 - acc: 0.3290\n",
      "Epoch 14/20\n",
      "2459/2459 [==============================] - 70s 29ms/step - loss: 0.0223 - acc: 0.3392\n",
      "Epoch 15/20\n",
      "2459/2459 [==============================] - 62s 25ms/step - loss: 0.0217 - acc: 0.3404\n",
      "Epoch 16/20\n",
      "2459/2459 [==============================] - 63s 26ms/step - loss: 0.0212 - acc: 0.3562\n",
      "Epoch 17/20\n",
      "2459/2459 [==============================] - 62s 25ms/step - loss: 0.0200 - acc: 0.3538\n",
      "Epoch 18/20\n",
      "2459/2459 [==============================] - 62s 25ms/step - loss: 0.0197 - acc: 0.3611\n",
      "Epoch 19/20\n",
      "2459/2459 [==============================] - 62s 25ms/step - loss: 0.0191 - acc: 0.3758\n",
      "Epoch 20/20\n",
      "2459/2459 [==============================] - 62s 25ms/step - loss: 0.0192 - acc: 0.3583\n"
     ]
    }
   ],
   "source": [
    "# Train 2D CNN model\n",
    "model2.fit(X_abs_2d, S_abs_T, epochs=20, batch_size=32)\n",
    "model2.save(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def denoise_sound_conv2(input_file_name, output_file_name):\n",
    "    sn, sr=librosa.load(input_file_name, sr=None)\n",
    "    testX=librosa.stft(sn, n_fft=1024, hop_length=512)\n",
    "    testX_abs = np.abs(testX)\n",
    "    testX_abs_pad = np.abs(padding_frames(testX))\n",
    "    X_abs_2d = imageize_spec(testX_abs_pad.T)\n",
    "    S_test_abs = model2.predict(X_abs_2d).T.reshape(513, -1)\n",
    "    ratio = (testX / testX_abs)\n",
    "    Sh = np.multiply(ratio, S_test_abs)\n",
    "    librosa.output.write_wav(output_file_name, librosa.istft(Sh, hop_length=512), sr)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "denoise_sound_conv2('data/test_x_01.wav', 'recover_01_d2.wav')\n",
    "denoise_sound_conv2('data/test_x_02.wav', 'recover_02_d2.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate SNR by training data\n",
    "testX_abs = X_abs\n",
    "testX_pad = X_abs\n",
    "# padding\n",
    "for i in range(19):\n",
    "    testX_pad = np.hstack((testX_pad, np.zeros((513, 1))))\n",
    "testX_abs_pad = np.abs(testX_pad)\n",
    "\n",
    "X_abs_2d = imageize_spec(testX_abs_pad.T)\n",
    "S_test_abs = model2.predict(X_abs_2d).T.reshape(513, -1)\n",
    "\n",
    "ratio = (X / X_abs)\n",
    "s_t = np.multiply(ratio, S_test_abs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.147324825076792\n"
     ]
    }
   ],
   "source": [
    "# Calculate SNR\n",
    "print(calculateSNR(S, s_t))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Result\n",
    "\n",
    "I found the training time of 1D CNN is faster than 2D CNN, since I can fit all the data into one epoch to train the model. \n",
    "\n",
    "In addition, even the SNR of 2D CNN can be as good as the 1D CNN, I still feel the quality of 1D CNN is much better than 2D CNN based on my subjective listening test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
