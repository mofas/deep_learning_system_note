{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv1D, Flatten, BatchNormalization\n",
    "\n",
    "import librosa\n",
    "import math\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(513, 2459)\n",
      "(513, 2459)\n"
     ]
    }
   ],
   "source": [
    "s, sr_s=librosa.load('data/train_clean_male.wav', sr=None)\n",
    "S=librosa.stft(s, n_fft=1024, hop_length=512)\n",
    "sn, sr_x=librosa.load('data/train_dirty_male.wav', sr=None)\n",
    "X=librosa.stft(sn, n_fft=1024, hop_length=512)\n",
    "print(S.shape)\n",
    "print(X.shape)\n",
    "S_abs = np.abs(S)\n",
    "X_abs = np.abs(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LEARNING_RATE = 1e-3\n",
    "# BATCH_SIZE = 64\n",
    "\n",
    "# # https://riptutorial.com/tensorflow/example/19385/basic-example\n",
    "# # https://towardsdatascience.com/applied-deep-learning-part-4-convolutional-neural-networks-584bc134c1e2\n",
    "# # https://towardsdatascience.com/the-4-convolutional-neural-network-models-that-can-classify-your-fashion-images-9fe7f3e5399d\n",
    "\n",
    "# # input of length -1, and dimension 513.\n",
    "# x = tf.placeholder(tf.float32, [BATCH_SIZE, 1, 513])\n",
    "# y_ = tf.placeholder(tf.float32, [BATCH_SIZE, 1, 513])\n",
    "\n",
    "# # filter with width 3, and we take 513 channels as input, and output also 100 channels.\n",
    "# filters = tf.Variable(tf.random_normal([3,513,100]))\n",
    "\n",
    "# conv1 = tf.nn.conv1d(\n",
    "#     x,            \n",
    "#     filters=filters,\n",
    "#     padding=\"SAME\",\n",
    "#     stride=1)\n",
    "\n",
    "# l1 = tf.layers.dense(conv1, units=200,  activation=tf.nn.relu)\n",
    "# l2 = tf.layers.dense(l1, units=200,  activation=tf.nn.relu)\n",
    "# y = tf.layers.dense(l2, units=513, activation=tf.nn.relu)\n",
    "\n",
    "# loss = tf.losses.mean_pairwise_squared_error(labels=y_, predictions=y)\n",
    "# # train_step = tf.train.GradientDescentOptimizer(learning_rate=LEARNING_RATE).minimize(loss)\n",
    "\n",
    "# sess=tf.Session()\n",
    "# tf.global_variables_initializer().run(session=sess)\n",
    "\n",
    "\n",
    "                                   \n",
    "# train_data = tf.data.Dataset.from_tensor_slices(tf.constant(X_abs.T[:]))\n",
    "# label_data = tf.data.Dataset.from_tensor_slices(tf.constant(S_abs.T[:]))\n",
    "# zip_data = tf.data.Dataset.zip((train_data, label_data))\n",
    "# batch_data = zip_data.batch(BATCH_SIZE).repeat()\n",
    "\n",
    "# # try \n",
    "# # batch_data = tf.data.Dataset.from_tensor_slices((tf.constant(X_abs.T[:]), tf.constant(S_abs.T[:])).batch(BATCH_SIZE).repeat()\n",
    "\n",
    "# iterator = batch_data.make_one_shot_iterator()\n",
    "# next_batch = iterator.get_next()\n",
    "\n",
    "# # https://www.tensorflow.org/guide/saved_model#models\n",
    "# saver = tf.train.Saver()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHECK_POINT_FILE_NAME = \"/tmp/hw2_1.ckpt\"\n",
    "# saver.restore(sess, CHECK_POINT_FILE_NAME)\n",
    "\n",
    "# TRAIN_STEPS = 50000\n",
    "# for i in range(TRAIN_STEPS+1):    \n",
    "#     batch = sess.run(next_batch)\n",
    "#     _, loss_value = sess.run((train_step, loss), feed_dict={x: batch[0], y_: batch[1]})\n",
    "#     if i% 2000 == 0:\n",
    "#         print('Training Step:' + str(i) + '  Loss =  ' + str(loss_value))\n",
    "        \n",
    "# # save model\n",
    "# save_path = saver.save(sess, CHECK_POINT_FILE_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://towardsdatascience.com/building-a-convolutional-neural-network-cnn-in-keras-329fbbadc5f5\n",
    "# Try Keras\n",
    "\n",
    "#create model\n",
    "model = Sequential()\n",
    "#add model layers\n",
    "model.add(Conv1D(128, kernel_size=3, activation='relu', input_shape=(513,1)))\n",
    "model.add(Conv1D(64, kernel_size=3, activation='relu'))\n",
    "model.add(Flatten())\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(300, activation='relu'))\n",
    "model.add(Dense(300, activation='relu'))\n",
    "model.add(Dense(513, activation='relu'))\n",
    "\n",
    "#compile model using accuracy to measure model performance\n",
    "model.compile(optimizer='adam', loss='mean_squared_error', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "2459/2459 [==============================] - 22s 9ms/step - loss: 0.0483 - acc: 0.2041\n",
      "Epoch 2/10\n",
      "2459/2459 [==============================] - 20s 8ms/step - loss: 0.0269 - acc: 0.2924\n",
      "Epoch 3/10\n",
      "2459/2459 [==============================] - 21s 8ms/step - loss: 0.0254 - acc: 0.3172\n",
      "Epoch 4/10\n",
      "2459/2459 [==============================] - 20s 8ms/step - loss: 0.0215 - acc: 0.3310\n",
      "Epoch 5/10\n",
      "2459/2459 [==============================] - 20s 8ms/step - loss: 0.0208 - acc: 0.3347\n",
      "Epoch 6/10\n",
      "2459/2459 [==============================] - 20s 8ms/step - loss: 0.0194 - acc: 0.3562\n",
      "Epoch 7/10\n",
      "2459/2459 [==============================] - 20s 8ms/step - loss: 0.0184 - acc: 0.3587\n",
      "Epoch 8/10\n",
      "2080/2459 [========================>.....] - ETA: 3s - loss: 0.0161 - acc: 0.3476"
     ]
    }
   ],
   "source": [
    "X_train = X_abs.T[:].reshape(-1, 513, 1)\n",
    "y_train = S_abs.T[:]\n",
    "\n",
    "model.fit(X_train, y_train, epochs=10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "def denoise_sound(input_file_name, output_file_name):\n",
    "    sn, sr=librosa.load(input_file_name, sr=None)\n",
    "    testX=librosa.stft(sn, n_fft=1024, hop_length=512)\n",
    "    print(testX.shape)\n",
    "    testX_abs = np.abs(testX)\n",
    "#     S_test_abs = sess.run(y, feed_dict={x: testX_abs.T}).T\n",
    "    S_test_abs = model.predict(testX_abs.T.reshape(-1, 513, 1)).T.reshape(513, -1)\n",
    "#     print(testX.shape, testX_abs.shape)\n",
    "    ratio = (testX / testX_abs)\n",
    "    Sh = np.multiply(ratio, S_test_abs)\n",
    "#     print(Sh.shape)\n",
    "    librosa.output.write_wav(output_file_name, librosa.istft(Sh, hop_length=512), sr)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(513, 142)\n",
      "(513, 380)\n"
     ]
    }
   ],
   "source": [
    "denoise_sound('data/test_x_01.wav', 'recover_01.wav')\n",
    "denoise_sound('data/test_x_02.wav', 'recover_02.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
