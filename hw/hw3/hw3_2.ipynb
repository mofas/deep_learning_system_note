{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import math\n",
    "import librosa\n",
    "\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate SNR \n",
    "def calculateSNR(st, st_h):\n",
    "    st_sum = np.sum(np.abs(st))\n",
    "    diff_sum = np.sum(np.abs(st-st_h))\n",
    "    return 10*math.log(st_sum**2/diff_sum**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data\n",
    "\n",
    "def read_data(path, prefix, files_to_load):\n",
    "    signal = np.zeros((513, 0))\n",
    "    noise = np.zeros((513, 0))\n",
    "    mixture = np.zeros((513, 0))\n",
    "    for i in range(files_to_load):\n",
    "        s, _=librosa.load('{}/{}s{:04d}.wav'.format(path, prefix, i), sr=None)\n",
    "        S=librosa.stft(s, n_fft=1024, hop_length=512)\n",
    "        signal = np.hstack((signal, S))\n",
    "        s, _=librosa.load('{}/{}n{:04d}.wav'.format(path, prefix, i), sr=None)\n",
    "        S=librosa.stft(s, n_fft=1024, hop_length=512)\n",
    "        noise = np.hstack((noise, S))\n",
    "        s, _=librosa.load('{}/{}x{:04d}.wav'.format(path, prefix, i), sr=None)\n",
    "        S=librosa.stft(s, n_fft=1024, hop_length=512)\n",
    "        mixture = np.hstack((mixture , S))\n",
    "\n",
    "    return signal, noise, mixture\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAIN_DATA_LEN = 1199\n",
    "TRAIN_DATA_LEN = 50\n",
    "signal, noise, mixture = read_data('timit-homework/tr', 'tr', TRAIN_DATA_LEN)\n",
    "v_signal, v_noise, v_mixture = read_data('timit-homework/v', 'v', 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(513, 4310)\n",
      "(513, 4310)\n"
     ]
    }
   ],
   "source": [
    "print(signal.shape)\n",
    "print(v_signal.shape)\n",
    "# Try to output~\n",
    "sr = 16000\n",
    "# librosa.output.write_wav(\"./test_concat.wav\", librosa.istft(signal, hop_length=512), sr)\n",
    "# librosa.output.write_wav(\"./v_test_concat.wav\", librosa.istft(v_mixture, hop_length=512), sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Preprocess data\n",
    "signal_abs = np.abs(signal)\n",
    "noise_abs = np.abs(noise)\n",
    "mixture_abs = np.abs(mixture)\n",
    "\n",
    "signal_T = signal.T\n",
    "noise_T = noise.T\n",
    "mixture_T = mixture.T\n",
    "signal_abs_T = signal_abs.T\n",
    "noise_abs_T = noise_abs.T\n",
    "mixture_abs_T = mixture_abs.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For validation data \n",
    "# Preprocess Data\n",
    "v_signal_abs = np.abs(v_signal)\n",
    "v_noise_abs = np.abs(v_noise)\n",
    "v_mixture_abs = np.abs(v_mixture)\n",
    "\n",
    "v_signal_T = v_signal.T\n",
    "v_noise_T = v_noise.T\n",
    "v_mixture_T = v_mixture.T\n",
    "v_signal_abs_T = v_signal_abs.T\n",
    "v_noise_abs_T = v_noise_abs.T\n",
    "v_mixture_abs_T = v_mixture_abs.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate IBM \n",
    "def get_M(signal, noise):\n",
    "    M = np.zeros_like(signal)\n",
    "    (ht, wd) = M.shape\n",
    "    for i in range(ht):\n",
    "        for j in range(wd):\n",
    "            if signal_abs_T[i][j] > noise_abs_T[i][j]:\n",
    "                M[i][j] = 1\n",
    "    return M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_M = get_M(signal_abs_T, signal_abs_T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "v_M = get_M(v_signal_abs_T, v_signal_abs_T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4310, 513) (4310, 513)\n",
      "(4310, 513) (4310, 513)\n"
     ]
    }
   ],
   "source": [
    "# Sanity check the shape of X(mixture) and M\n",
    "print(mixture_abs_T.shape, train_M.shape)\n",
    "print(v_mixture_abs_T.shape, v_M.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing M \n",
    "v_S_recover = v_M * mixture_T\n",
    "# print(v_S_recover.shape)\n",
    "sr = 16000\n",
    "# librosa.output.write_wav(\"./v_before_recover.wav\", librosa.istft(mixture, hop_length=512), sr)\n",
    "# librosa.output.write_wav(\"./v_recover.wav\", librosa.istft(v_S_recover.T, hop_length=512), sr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Training Parameters\n",
    "learning_rate = 0.001\n",
    "training_steps = 10000\n",
    "batch_size = 128\n",
    "\n",
    "# Network Parameters\n",
    "num_input = 513   # total data input (513 channel)\n",
    "time_steps = 8   #\n",
    "num_hidden = 128  # hidden layer num of features\n",
    "num_classes = 513 # total classes (513 channel)\n",
    "\n",
    "is_training = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.variable_scope(\"rnn_model\", reuse=tf.AUTO_REUSE):\n",
    "    X = tf.placeholder(\"float\", [None, time_steps, num_input])\n",
    "    Y = tf.placeholder(\"float\", [None, num_classes])\n",
    "\n",
    "# batch_size*128*513\n",
    "weights = {\n",
    "    'out': tf.Variable(tf.random_normal([num_hidden, num_classes]))\n",
    "}\n",
    "\n",
    "biases = {\n",
    "    'out': tf.Variable(tf.random_normal([num_classes]))\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.reset_default_graph()\n",
    "\n",
    "def RNN(x, weights, biases):    \n",
    "    # Prepare data shape to match `rnn` function requirements\n",
    "    # Current data input shape: (batch_size, timesteps, n_input)\n",
    "    # Required shape: 'timesteps' tensors list of shape (batch_size, n_input)\n",
    "    # Unstack to get a list of 'timesteps' tensors of shape (batch_size, n_input)\n",
    "    x = tf.unstack(x, axis=1)\n",
    "\n",
    "    # Define a lstm cell with tensorflow\n",
    "    lstm_cell = tf.nn.rnn_cell.BasicLSTMCell(num_hidden)\n",
    "    # Get lstm cell output\n",
    "    outputs, states = tf.nn.static_rnn(lstm_cell, x, dtype=tf.float32)\n",
    "    outputs = [ tf.matmul(output, weights['out']) + biases['out'] for output in outputs]\n",
    "    stack_outputs = tf.stack(outputs)\n",
    "\n",
    "    return tf.reshape(stack_outputs, (-1, num_classes))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Calculate loss, train_op\n",
    "with tf.variable_scope(\"rnn_model\", reuse=tf.AUTO_REUSE):\n",
    "    Y_pred = RNN(X, weights, biases)\n",
    "    loss = tf.losses.mean_squared_error(labels=Y, predictions=Y_pred)\n",
    "    train_op = tf.train.AdamOptimizer(learning_rate).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 513) (?, 513)\n"
     ]
    }
   ],
   "source": [
    "print(Y_pred.shape, Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create batch data for training\n",
    "train_data = tf.data.Dataset.from_tensor_slices(tf.constant(mixture_abs_T))\n",
    "label_data = tf.data.Dataset.from_tensor_slices(tf.constant(M.reshape(-1, num_classes)))\n",
    "batch_data = tf.data.Dataset.zip((train_data, label_data)).repeat().batch(batch_size)\n",
    "\n",
    "iterator = batch_data.make_one_shot_iterator()\n",
    "next_batch = iterator.get_next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4310\n",
      "(4312, 513) (4312, 513)\n"
     ]
    }
   ],
   "source": [
    "# Add Padding, \n",
    "def fit_RNN_input_dim(data, label):\n",
    "    (row, _) = data.shape\n",
    "    print(row)\n",
    "    while row % time_steps != 0:\n",
    "        data = np.vstack((data, np.zeros(num_input)))\n",
    "        label = np.vstack((label, np.zeros(num_input)))\n",
    "        row += 1\n",
    "    \n",
    "    return data, label\n",
    "    \n",
    "v_mixture_abs_T_fit, v_M_fit = fit_RNN_input_dim(v_mixture_abs_T, v_M)\n",
    "\n",
    "print(v_mixture_abs_T_fit.shape, v_M_fit.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial session\n",
    "sess=tf.Session()\n",
    "tf.global_variables_initializer().run(session=sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create checkpoint\n",
    "saver = tf.train.Saver()\n",
    "CHECK_POINT_FILE_NAME = \"./hw3_2.ckpt\"\n",
    "\n",
    "try:\n",
    "    saver.restore(sess, CHECK_POINT_FILE_NAME)\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step:0  Accuracy =  0.23734966  Loss =  0.18094409\n",
      "Training Step:500  Accuracy =  0.23546435  Loss =  0.23945925\n",
      "Training Step:1000  Accuracy =  0.23612012  Loss =  0.27440012\n",
      "Training Step:1500  Accuracy =  0.23785299  Loss =  0.26867792\n",
      "Training Step:2000  Accuracy =  0.2387508  Loss =  0.23705155\n",
      "Training Step:2500  Accuracy =  0.23886047  Loss =  0.18743317\n",
      "Training Step:3000  Accuracy =  0.23716904  Loss =  0.18975642\n",
      "Training Step:3500  Accuracy =  0.2359404  Loss =  0.2661727\n",
      "Training Step:4000  Accuracy =  0.23538412  Loss =  0.23644198\n",
      "Training Step:4500  Accuracy =  0.23568231  Loss =  0.19328924\n",
      "Training Step:5000  Accuracy =  0.23790792  Loss =  0.1918992\n",
      "Training Step:5500  Accuracy =  0.23748426  Loss =  0.17660941\n",
      "Training Step:6000  Accuracy =  0.23965931  Loss =  0.1956235\n",
      "Training Step:6500  Accuracy =  0.24040137  Loss =  0.18700877\n",
      "Training Step:7000  Accuracy =  0.23723778  Loss =  0.2601164\n",
      "Training Step:7500  Accuracy =  0.23662151  Loss =  0.24319452\n",
      "Training Step:8000  Accuracy =  0.23497953  Loss =  0.2188132\n",
      "Training Step:8500  Accuracy =  0.23717359  Loss =  0.16796477\n",
      "Training Step:9000  Accuracy =  0.23840126  Loss =  0.23043852\n",
      "Training Step:9500  Accuracy =  0.24130693  Loss =  0.1733716\n",
      "Training Step:10000  Accuracy =  0.24473603  Loss =  0.12766394\n"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "for i in range(training_steps+1):\n",
    "    (batch_x, batch_y) = sess.run(next_batch)\n",
    "    batch_x = batch_x.reshape(-1, time_steps, num_input)\n",
    "#     print(batch_x.shape, batch_y.shape)\n",
    "    _, loss_value = sess.run((train_op, loss), feed_dict={X: batch_x, Y: batch_y})\n",
    "    if i % 1000 == 0:\n",
    "        is_training = False\n",
    "        print('Training Step:' + str(i) + '  Accuracy =  ' + \n",
    "              str(sess.run(loss, feed_dict={X: v_mixture_abs_T_fit.reshape(-1, time_steps, num_input), Y: v_M_fit})) + \n",
    "              '  Loss =  ' + str(loss_value))\n",
    "        is_training = True\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
