{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import math\n",
    "import librosa\n",
    "\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate SNR \n",
    "def calculateSNR(st, st_h):\n",
    "    st_sum = np.sum(np.abs(st))\n",
    "    diff_sum = np.sum(np.abs(st-st_h))\n",
    "    return 10*math.log(st_sum**2/diff_sum**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data\n",
    "\n",
    "def read_data(path, prefix, files_to_load):\n",
    "    signal = np.zeros((513, 0))\n",
    "    noise = np.zeros((513, 0))\n",
    "    mixture = np.zeros((513, 0))\n",
    "    for i in range(files_to_load):\n",
    "        s, _=librosa.load('{}/{}s{:04d}.wav'.format(path, prefix, i), sr=None)\n",
    "        S=librosa.stft(s, n_fft=1024, hop_length=512)\n",
    "        signal = np.hstack((signal, S))\n",
    "        s, _=librosa.load('{}/{}n{:04d}.wav'.format(path, prefix, i), sr=None)\n",
    "        S=librosa.stft(s, n_fft=1024, hop_length=512)\n",
    "        noise = np.hstack((noise, S))\n",
    "        s, _=librosa.load('{}/{}x{:04d}.wav'.format(path, prefix, i), sr=None)\n",
    "        S=librosa.stft(s, n_fft=1024, hop_length=512)\n",
    "        mixture = np.hstack((mixture , S))\n",
    "\n",
    "    return signal, noise, mixture\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAIN_DATA_LEN = 1199\n",
    "TRAIN_DATA_LEN = 50\n",
    "signal, noise, mixture = read_data('timit-homework/tr', 'tr', TRAIN_DATA_LEN)\n",
    "v_signal, v_noise, v_mixture = read_data('timit-homework/v', 'v', 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(513, 4310)\n",
      "(513, 4310)\n"
     ]
    }
   ],
   "source": [
    "print(signal.shape)\n",
    "print(v_signal.shape)\n",
    "# Try to output~\n",
    "# _, sr = librosa.load('timit-homework/tr/trs0000.wav', sr=None)\n",
    "# librosa.output.write_wav(\"./test_concat.wav\", librosa.istft(signal, hop_length=512), sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Get abs of training data\n",
    "signal_abs = np.abs(signal)\n",
    "noise_abs = np.abs(noise)\n",
    "mixture_abs = np.abs(mixture)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# short hand for common used \n",
    "signal_T = signal.T\n",
    "noise_T = noise.T\n",
    "mixture_T = mixture.T\n",
    "signal_abs_T = signal_abs.T\n",
    "noise_abs_T = noise_abs.T\n",
    "mixture_abs_T = mixture_abs.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate IBM \n",
    "M = np.zeros_like(signal_abs_T)\n",
    "(ht, wd) = M.shape\n",
    "\n",
    "for i in range(ht):\n",
    "    for j in range(wd):\n",
    "        if signal_abs_T[i][j] > noise_abs_T[i][j]:\n",
    "            M[i][j] = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4310, 513) (4310, 513)\n"
     ]
    }
   ],
   "source": [
    "# Sanity check the shape of X(mixture) and M\n",
    "print(mixture_abs_T.shape, M.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Training Parameters\n",
    "learning_rate = 0.001\n",
    "training_steps = 10000\n",
    "batch_size = 128\n",
    "\n",
    "# Network Parameters\n",
    "num_input = 513   # total data input (513 channel)\n",
    "time_steps = 8   #\n",
    "num_hidden = 128  # hidden layer num of features\n",
    "num_classes = 513 # total classes (513 channel)\n",
    "\n",
    "is_training = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.variable_scope(\"rnn_model\", reuse=tf.AUTO_REUSE):\n",
    "    X = tf.placeholder(\"float\", [None, time_steps, num_input])\n",
    "    Y = tf.placeholder(\"float\", [None, num_classes])\n",
    "\n",
    "# batch_size*128*513\n",
    "weights = {\n",
    "    'out': tf.Variable(tf.random_normal([num_hidden, num_classes]))\n",
    "}\n",
    "\n",
    "biases = {\n",
    "    'out': tf.Variable(tf.random_normal([num_classes]))\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.reset_default_graph()\n",
    "\n",
    "def RNN(x, weights, biases):    \n",
    "    # Prepare data shape to match `rnn` function requirements\n",
    "    # Current data input shape: (batch_size, timesteps, n_input)\n",
    "    # Required shape: 'timesteps' tensors list of shape (batch_size, n_input)\n",
    "    # Unstack to get a list of 'timesteps' tensors of shape (batch_size, n_input)\n",
    "    x = tf.unstack(x, axis=1)\n",
    "\n",
    "    # Define a lstm cell with tensorflow\n",
    "    lstm_cell = tf.nn.rnn_cell.BasicLSTMCell(num_hidden)\n",
    "    # Get lstm cell output\n",
    "    outputs, states = tf.nn.static_rnn(lstm_cell, x, dtype=tf.float32)\n",
    "    outputs = [ tf.matmul(output, weights['out']) + biases['out'] for output in outputs]\n",
    "    stack_outputs = tf.stack(outputs)\n",
    "\n",
    "    return tf.reshape(stack_outputs, (-1, num_classes))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Calculate loss, train_op\n",
    "with tf.variable_scope(\"rnn_model\", reuse=tf.AUTO_REUSE):\n",
    "    Y_pred = RNN(X, weights, biases)\n",
    "    loss = tf.losses.mean_squared_error(labels=Y, predictions=Y_pred)\n",
    "    train_op = tf.train.AdamOptimizer(learning_rate).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 513) (?, 513)\n"
     ]
    }
   ],
   "source": [
    "print(Y_pred.shape, Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = tf.data.Dataset.from_tensor_slices(tf.constant(mixture_abs_T))\n",
    "label_data = tf.data.Dataset.from_tensor_slices(tf.constant(M.reshape(-1, num_classes)))\n",
    "batch_data = tf.data.Dataset.zip((train_data, label_data)).repeat().batch(batch_size)\n",
    "\n",
    "iterator = batch_data.make_one_shot_iterator()\n",
    "next_batch = iterator.get_next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial session\n",
    "sess=tf.Session()\n",
    "tf.global_variables_initializer().run(session=sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create checkpoint\n",
    "saver = tf.train.Saver()\n",
    "CHECK_POINT_FILE_NAME = \"./hw3_2.ckpt\"\n",
    "\n",
    "try:\n",
    "    saver.restore(sess, CHECK_POINT_FILE_NAME)\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16, 8, 513) (128, 513)\n",
      "(16, 8, 513) (128, 513)\n"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "# for i in range(training_steps+1):\n",
    "for i in range(1000):\n",
    "    (batch_x, batch_y) = sess.run(next_batch)\n",
    "    batch_x = batch_x.reshape(-1, time_steps, num_input)\n",
    "#     print(batch_x.shape, batch_y.shape)\n",
    "    _, loss_value = sess.run((train_op, loss), feed_dict={X: batch_x, Y: batch_y})\n",
    "    if i % 200 == 0:\n",
    "        is_training = False\n",
    "        print('Training Step:' + str(i) + '  Accuracy =  ' + \n",
    "              str(sess.run(accuracy, feed_dict={x: mixture_abs_T, y_: mnist.test.labels})) + \n",
    "              '  Loss =  ' + str(loss_value))\n",
    "        is_training = True\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
