{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import math\n",
    "import librosa\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate SNR \n",
    "def calculateSNR(st, st_h):\n",
    "    st_sum = np.sum(np.abs(st))\n",
    "    diff_sum = np.sum(np.abs(st-st_h))\n",
    "    return 10*math.log(st_sum**2/diff_sum**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data\n",
    "\n",
    "def read_data(path, prefix, files_to_load):\n",
    "    signal = np.zeros((513, 0))\n",
    "    noise = np.zeros((513, 0))\n",
    "    mixture = np.zeros((513, 0))\n",
    "    for i in range(files_to_load):\n",
    "        s, _=librosa.load('{}/{}s{:04d}.wav'.format(path, prefix, i), sr=None)\n",
    "        S=librosa.stft(s, n_fft=1024, hop_length=512)\n",
    "        signal = np.hstack((signal, S))\n",
    "        s, _=librosa.load('{}/{}n{:04d}.wav'.format(path, prefix, i), sr=None)\n",
    "        S=librosa.stft(s, n_fft=1024, hop_length=512)\n",
    "        noise = np.hstack((noise, S))\n",
    "        s, _=librosa.load('{}/{}x{:04d}.wav'.format(path, prefix, i), sr=None)\n",
    "        S=librosa.stft(s, n_fft=1024, hop_length=512)\n",
    "        mixture = np.hstack((mixture , S))\n",
    "\n",
    "    return signal, noise, mixture\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DATA_LEN = 600\n",
    "# TRAIN_DATA_LEN = 1200\n",
    "signal, noise, mixture = read_data('timit-homework/tr', 'tr', TRAIN_DATA_LEN)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "v_signal, v_noise, v_mixture = read_data('timit-homework/v', 'v', 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(513, 58900)\n",
      "(513, 4310)\n"
     ]
    }
   ],
   "source": [
    "print(signal.shape)\n",
    "print(v_signal.shape)\n",
    "# Try to output~\n",
    "sr = 16000\n",
    "# librosa.output.write_wav(\"./test_concat.wav\", librosa.istft(signal, hop_length=512), sr)\n",
    "# librosa.output.write_wav(\"./v_test_concat.wav\", librosa.istft(v_mixture, hop_length=512), sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Preprocess data\n",
    "signal_abs = np.abs(signal)\n",
    "noise_abs = np.abs(noise)\n",
    "mixture_abs = np.abs(mixture)\n",
    "\n",
    "signal_T = signal.T\n",
    "noise_T = noise.T\n",
    "mixture_T = mixture.T\n",
    "signal_abs_T = signal_abs.T\n",
    "noise_abs_T = noise_abs.T\n",
    "mixture_abs_T = mixture_abs.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For validation data \n",
    "# Preprocess Data\n",
    "v_signal_abs = np.abs(v_signal)\n",
    "v_noise_abs = np.abs(v_noise)\n",
    "v_mixture_abs = np.abs(v_mixture)\n",
    "\n",
    "v_signal_T = v_signal.T\n",
    "v_noise_T = v_noise.T\n",
    "v_mixture_T = v_mixture.T\n",
    "v_signal_abs_T = v_signal_abs.T\n",
    "v_noise_abs_T = v_noise_abs.T\n",
    "v_mixture_abs_T = v_mixture_abs.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate IBM \n",
    "def get_M(signal, noise):\n",
    "    M = np.zeros_like(signal)\n",
    "    (ht, wd) = M.shape\n",
    "    for i in range(ht):\n",
    "        for j in range(wd):\n",
    "            if signal_abs_T[i][j] > noise_abs_T[i][j]:\n",
    "                M[i][j] = 1\n",
    "    return M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_M = get_M(signal_abs_T, signal_abs_T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "v_M = get_M(v_signal_abs_T, v_signal_abs_T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(58900, 513) (58900, 513)\n",
      "(18610, 513) (18610, 513)\n"
     ]
    }
   ],
   "source": [
    "# Sanity check the shape of X(mixture) and M\n",
    "print(mixture_abs_T.shape, train_M.shape)\n",
    "print(v_mixture_abs_T.shape, v_M.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing M \n",
    "signal_recover = train_M * mixture_T\n",
    "v_signal_recover = v_M * v_mixture_T\n",
    "sr = 16000\n",
    "# librosa.output.write_wav(\"./v_before_recover.wav\", librosa.istft(mixture, hop_length=512), sr)\n",
    "# librosa.output.write_wav(\"./v_recover.wav\", librosa.istft(v_signal_recover.T, hop_length=512), sr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24.732813943612374\n",
      "12.992788440628296\n"
     ]
    }
   ],
   "source": [
    "# Test SNR based on v_signal_recover\n",
    "print(calculateSNR(signal, signal_recover.T))\n",
    "print(calculateSNR(v_signal, v_signal_recover.T))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Training Parameters\n",
    "learning_rate = 0.001\n",
    "batch_size = 128\n",
    "\n",
    "# Network Parameters\n",
    "num_input = 513   # total data input (513 channel)\n",
    "time_steps = 8   #\n",
    "num_hidden = 128  # hidden layer num of features\n",
    "num_classes = 513 # total classes (513 channel)\n",
    "\n",
    "is_training = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.variable_scope(\"rnn_model\", reuse=tf.AUTO_REUSE):\n",
    "    X = tf.placeholder(\"float\", [None, time_steps, num_input])\n",
    "    Y = tf.placeholder(\"float\", [None, num_classes])\n",
    "\n",
    "# batch_size*128*513\n",
    "weights = [tf.Variable(tf.random_normal([num_hidden, num_classes])) for i in range(time_steps)]\n",
    "\n",
    "biases = [tf.Variable(tf.random_normal([num_classes])) for i in range(time_steps)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.reset_default_graph()\n",
    "\n",
    "def RNN(x, weights, biases):    \n",
    "    # Prepare data shape to match `rnn` function requirements\n",
    "    # Current data input shape: (batch_size, timesteps, n_input)\n",
    "    # Required shape: 'timesteps' tensors list of shape (batch_size, n_input)\n",
    "    # Unstack to get a list of 'timesteps' tensors of shape (batch_size, n_input)\n",
    "    x = tf.unstack(x, axis=1)\n",
    "\n",
    "    # Define a lstm cell with tensorflow\n",
    "    lstm_cell = tf.nn.rnn_cell.BasicLSTMCell(num_hidden)\n",
    "    # Get lstm cell output\n",
    "    outputs, states = tf.nn.static_rnn(lstm_cell, x, dtype=tf.float32)    \n",
    "    ret_outputs = []\n",
    "    for i in range(len(outputs)):        \n",
    "        ret_outputs.append(tf.matmul(outputs[i], weights[i]) + biases[i])\n",
    "    stack_outputs = tf.stack(ret_outputs)\n",
    "\n",
    "    return tf.reshape(stack_outputs, (-1, num_classes))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Calculate loss, train_op\n",
    "with tf.variable_scope(\"rnn_model\", reuse=tf.AUTO_REUSE):\n",
    "    Y_pred = RNN(X, weights, biases)\n",
    "    loss = tf.losses.mean_squared_error(labels=Y, predictions=Y_pred)\n",
    "    train_op = tf.train.AdamOptimizer(learning_rate).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 513) (?, 513)\n"
     ]
    }
   ],
   "source": [
    "print(Y_pred.shape, Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create batch data for training\n",
    "train_data = tf.data.Dataset.from_tensor_slices(tf.constant(mixture_abs_T))\n",
    "label_data = tf.data.Dataset.from_tensor_slices(tf.constant(M.reshape(-1, num_classes)))\n",
    "batch_data = tf.data.Dataset.zip((train_data, label_data)).repeat().batch(batch_size)\n",
    "\n",
    "iterator = batch_data.make_one_shot_iterator()\n",
    "next_batch = iterator.get_next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add Padding, to \n",
    "def fit_RNN_input_dim(data):\n",
    "    (row, _) = data.shape\n",
    "    count = 0\n",
    "    while row % time_steps != 0:\n",
    "        data = np.vstack((data, np.zeros(num_input)))\n",
    "        row += 1\n",
    "        count += 1\n",
    "    \n",
    "    return data, count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4312, 513) (4312, 513)\n"
     ]
    }
   ],
   "source": [
    "(v_mixture_abs_T_fit, _) = fit_RNN_input_dim(v_mixture_abs_T)\n",
    "(v_M_fit, _) = fit_RNN_input_dim(v_M)\n",
    "print(v_mixture_abs_T_fit.shape, v_M_fit.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial session\n",
    "sess=tf.Session()\n",
    "tf.global_variables_initializer().run(session=sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create checkpoint\n",
    "saver = tf.train.Saver()\n",
    "CHECK_POINT_FILE_NAME = \"./hw3_2.ckpt\"\n",
    "\n",
    "try:\n",
    "    saver.restore(sess, CHECK_POINT_FILE_NAME)\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step:0  Validation Loss =  0.23965575Train Loss =  0.19815406\n",
      "Training Step:1000  Validation Loss =  0.24122183Train Loss =  0.23180456\n",
      "Training Step:2000  Validation Loss =  0.25111005Train Loss =  0.16151479\n",
      "Training Step:3000  Validation Loss =  0.243449Train Loss =  0.18703413\n",
      "Training Step:4000  Validation Loss =  0.24112882Train Loss =  0.20896038\n",
      "Training Step:5000  Validation Loss =  0.24442476Train Loss =  0.21313599\n",
      "Training Step:6000  Validation Loss =  0.24611773Train Loss =  0.16962238\n",
      "Training Step:7000  Validation Loss =  0.24323905Train Loss =  0.21467513\n",
      "Training Step:8000  Validation Loss =  0.2444713Train Loss =  0.17785412\n",
      "Training Step:9000  Validation Loss =  0.2453906Train Loss =  0.20531043\n",
      "Training Step:10000  Validation Loss =  0.24703872Train Loss =  0.19101194\n"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "training_steps = 10000\n",
    "for i in range(training_steps+1):\n",
    "    (batch_x, batch_y) = sess.run(next_batch)\n",
    "    batch_x = batch_x.reshape(-1, time_steps, num_input)\n",
    "#     print(batch_x.shape, batch_y.shape)\n",
    "    _, loss_value = sess.run((train_op, loss), feed_dict={X: batch_x, Y: batch_y})\n",
    "    if i % 1000 == 0:\n",
    "        is_training = False\n",
    "        print('Training Step:' + str(i) + '  Validation Loss =  ' + \n",
    "              str(sess.run(loss, feed_dict={X: v_mixture_abs_T_fit.reshape(-1, time_steps, num_input), Y: v_M_fit})) + \n",
    "              'Train Loss =  ' + str(loss_value))\n",
    "        is_training = True\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using 1 BasicLSTMCell\n",
    "Training Step:0  Validation Loss =  0.23965575Train Loss =  0.19815406\n",
    "Training Step:1000  Validation Loss =  0.24122183Train Loss =  0.23180456\n",
    "Training Step:2000  Validation Loss =  0.25111005Train Loss =  0.16151479\n",
    "Training Step:3000  Validation Loss =  0.243449Train Loss =  0.18703413\n",
    "Training Step:4000  Validation Loss =  0.24112882Train Loss =  0.20896038\n",
    "Training Step:5000  Validation Loss =  0.24442476Train Loss =  0.21313599\n",
    "Training Step:6000  Validation Loss =  0.24611773Train Loss =  0.16962238\n",
    "Training Step:7000  Validation Loss =  0.24323905Train Loss =  0.21467513\n",
    "Training Step:8000  Validation Loss =  0.2444713Train Loss =  0.17785412\n",
    "Training Step:9000  Validation Loss =  0.2453906Train Loss =  0.20531043\n",
    "Training Step:10000  Validation Loss =  0.24703872Train Loss =  0.19101194"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./hw3_2.ckpt'"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "saver.save(sess, CHECK_POINT_FILE_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get M for traiing data\n",
    "def recover_train(input_mixture, mixture_abs_T):\n",
    "    (mixture_fit, diff) = fit_RNN_input_dim(mixture_abs_T)\n",
    "    input_x = mixture_fit.reshape(-1, time_steps, num_input)\n",
    "    train_M = sess.run(Y_pred, feed_dict={X: input_x})\n",
    "    print(train_M.shape)\n",
    "    return train_M[:-diff] * input_mixture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(58904, 513)\n"
     ]
    }
   ],
   "source": [
    "recover_signal = recover_train(mixture_T, mixture_abs_T)\n",
    "# librosa.output.write_wav(\"./train_recover.wav\", librosa.istft(recover_signal.T, hop_length=512), sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18616, 513)\n"
     ]
    }
   ],
   "source": [
    "# Recover Validaion track!\n",
    "v_recover_signal = recover_train(v_mixture_T, v_mixture_abs_T)\n",
    "librosa.output.write_wav(\"./v_recover.wav\", librosa.istft(v_recover_signal.T, hop_length=512), sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.14415701616086762\n",
      "-0.08665901355862538\n"
     ]
    }
   ],
   "source": [
    "# Calculate SNR for training data and validation data\n",
    "print(calculateSNR(signal.T, recover_signal))\n",
    "print(calculateSNR(v_signal.T, v_recover_signal))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "librosa.output.write_wav(\"./v_mixture.wav\", librosa.istft(v_mixture, hop_length=512), sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
