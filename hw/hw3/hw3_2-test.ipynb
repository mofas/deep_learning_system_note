{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import math\n",
    "import librosa\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate SNR \n",
    "def calculateSNR(st, st_h):\n",
    "    st_sum = np.sum(np.abs(st))\n",
    "    diff_sum = np.sum(np.abs(st-st_h))\n",
    "    return 10*math.log(st_sum**2/diff_sum**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate IBM by given source signal and noise\n",
    "def get_M(signal, noise):\n",
    "    M = np.zeros_like(signal, dtype=np.int8)\n",
    "    (ht, wd) = M.shape\n",
    "    for i in range(ht):\n",
    "        for j in range(wd):\n",
    "            if signal[i][j] > noise[i][j]:\n",
    "                M[i][j] = 1\n",
    "    return M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Parameters\n",
    "learning_rate = 0.001\n",
    "batch_size = 8\n",
    "\n",
    "# Hyper Parameter\n",
    "time_steps = 8   #\n",
    "num_input = 513   # total data input (513 channel)\n",
    "num_classes = 513 # total classes (513 channel)\n",
    "num_hidden = 128  # hidden layer num of features\n",
    "keep_prob = 0.8\n",
    "\n",
    "\n",
    "is_training = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with tf.variable_scope(\"rnn_model\", reuse=tf.AUTO_REUSE):\n",
    "    X = tf.placeholder(\"float\", [None, time_steps, num_input])\n",
    "    Y = tf.placeholder(\"float\", [None, num_classes])\n",
    "    weight = tf.Variable(tf.random_normal([num_hidden, num_classes]))\n",
    "    bias = tf.Variable(tf.random_normal([num_classes]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RNN(x):    \n",
    "    # Define a lstm cell with tensorflow\n",
    "    cell1 = tf.contrib.rnn.DropoutWrapper(tf.contrib.cudnn_rnn.CudnnCompatibleLSTMCell(num_hidden), output_keep_prob=keep_prob)\n",
    "    cell2 = tf.contrib.rnn.DropoutWrapper(tf.contrib.cudnn_rnn.CudnnCompatibleLSTMCell(num_hidden), output_keep_prob=keep_prob)\n",
    "    cell3 = tf.contrib.rnn.DropoutWrapper(tf.contrib.cudnn_rnn.CudnnCompatibleLSTMCell(num_hidden), output_keep_prob=keep_prob)\n",
    "    cell = tf.nn.rnn_cell.MultiRNNCell([cell1, cell2, cell3])        \n",
    "    \n",
    "    outputs, states = tf.nn.dynamic_rnn(cell, x, dtype=tf.float32)    \n",
    "    ret = tf.matmul(tf.reshape(outputs, (-1, num_hidden)), weight) + bias\n",
    "    print(ret.shape)\n",
    "    return ret\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 513)\n"
     ]
    }
   ],
   "source": [
    "# Calculate loss, train_op\n",
    "with tf.variable_scope(\"rnn_model\", reuse=tf.AUTO_REUSE):\n",
    "    Y_pred = RNN(X)\n",
    "    loss = tf.losses.mean_squared_error(labels=Y, predictions=Y_pred)\n",
    "    train_op = tf.train.AdamOptimizer(learning_rate).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add Padding, to \n",
    "def fit_RNN_input_dim(data):\n",
    "    (row, _) = data.shape\n",
    "    count = 0\n",
    "    while row % time_steps != 0:\n",
    "        data = np.vstack((data, np.zeros(num_input)))\n",
    "        row += 1\n",
    "        count += 1\n",
    "    \n",
    "    return data, count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_file_data(i):\n",
    "    s, _=librosa.load('timit-homework/tr/trs{:04d}.wav'.format(i), sr=None)\n",
    "    signal = librosa.stft(s, n_fft=1024, hop_length=512)\n",
    "    s, _=librosa.load('timit-homework/tr/trn{:04d}.wav'.format(i), sr=None)\n",
    "    noise = librosa.stft(s, n_fft=1024, hop_length=512)\n",
    "    s, _=librosa.load('timit-homework/tr/trx{:04d}.wav'.format(i), sr=None)\n",
    "    mixture = librosa.stft(s, n_fft=1024, hop_length=512)\n",
    "    \n",
    "    signal_abs = np.abs(signal)\n",
    "    noise_abs = np.abs(noise)\n",
    "    mixture_abs = np.abs(mixture)\n",
    "\n",
    "    signal_T = signal.T\n",
    "    noise_T = noise.T\n",
    "    mixture_T = mixture.T\n",
    "    \n",
    "    signal_abs_T = signal_abs.T\n",
    "    noise_abs_T = noise_abs.T\n",
    "    mixture_abs_T = mixture_abs.T\n",
    "    \n",
    "    M = get_M(signal_abs_T, noise_abs_T)\n",
    "    \n",
    "    return [mixture_abs_T, M.reshape(-1, num_classes)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data_to_use = 1200\n",
    "\n",
    "# Create data stream for training\n",
    "dataset = tf.data.Dataset.range(data_to_use).map(\n",
    "    lambda idx: tuple(tf.py_func(process_file_data, [idx], [tf.float32, tf.int8]))).repeat()\n",
    "\n",
    "batch_data = dataset\n",
    "iterator = batch_data.make_one_shot_iterator()\n",
    "next_element = iterator.get_next()\n",
    "\n",
    "\n",
    "# Initial session\n",
    "sess=tf.Session()\n",
    "tf.global_variables_initializer().run(session=sess)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step:0  Train Loss =  1.1613156\n",
      "Training Step:1000  Train Loss =  0.20274538\n",
      "Training Step:2000  Train Loss =  0.21462098\n",
      "Training Step:3000  Train Loss =  0.14499989\n",
      "Training Step:4000  Train Loss =  0.14095008\n",
      "Training Step:5000  Train Loss =  0.1398262\n",
      "Training Step:6000  Train Loss =  0.103418596\n",
      "Training Step:7000  Train Loss =  0.09724436\n",
      "Training Step:8000  Train Loss =  0.14713061\n",
      "Training Step:9000  Train Loss =  0.111143224\n",
      "Training Step:10000  Train Loss =  0.12785242\n"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "training_steps = 10000\n",
    "for i in range(training_steps+1):\n",
    "    (batch_x, batch_y) = sess.run(next_element)\n",
    "    (batch_x_fit, _) = fit_RNN_input_dim(batch_x)\n",
    "    (batch_y_fit, _) = fit_RNN_input_dim(batch_y)\n",
    "    batch_x_fit = batch_x_fit.reshape(-1, time_steps, num_input)\n",
    "    \n",
    "    _, loss_value = sess.run((train_op, loss), feed_dict={X: batch_x_fit, Y: batch_y_fit})\n",
    "    if i % 1000 == 0:        \n",
    "        print('Training Step:' + str(i) + '  Train Loss =  ' + str(loss_value))\n",
    "#         print('Training Step:' + str(i) + '  Validation Loss =  ' + \n",
    "#               str(sess.run(loss, feed_dict={X: v_mixture_abs_T_fit.reshape(-1, time_steps, num_input), Y: v_M_fit})) + \n",
    "#               '  Train Loss =  ' + str(loss_value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get M for traiing data\n",
    "def recover_train(input_mixture, mixture_abs_T):\n",
    "    (mixture_fit, diff) = fit_RNN_input_dim(mixture_abs_T)\n",
    "    input_x = mixture_fit.reshape(-1, time_steps, num_input)\n",
    "    train_M = sess.run(Y_pred, feed_dict={X: input_x})\n",
    "    if diff > 0:\n",
    "        return train_M[:-diff] * input_mixture\n",
    "    return train_M * input_mixture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(118552, 513)\n"
     ]
    }
   ],
   "source": [
    "recover_signal = recover_train(mixture_T, mixture_abs_T)\n",
    "# librosa.output.write_wav(\"./train_recover.wav\", librosa.istft(recover_signal.T, hop_length=512), sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(118552, 513)\n"
     ]
    }
   ],
   "source": [
    "# Recover Validaion track!\n",
    "v_recover_signal = recover_train(v_mixture_T, v_mixture_abs_T)\n",
    "# librosa.output.write_wav(\"./v_recover_rnn.wav\", librosa.istft(v_recover_signal.T, hop_length=512), sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.795495739503428\n",
      "12.075764216524007\n"
     ]
    }
   ],
   "source": [
    "# Calculate SNR for training data and validation data\n",
    "print(calculateSNR(signal.T, recover_signal))\n",
    "print(calculateSNR(v_signal.T, v_recover_signal))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Recover test data\n",
    "def recover_test_data(path, target_path, files_to_load):\n",
    "    for i in range(files_to_load):\n",
    "        s, _=librosa.load('{}/tex{:04d}.wav'.format(path, i), sr=None)\n",
    "        S=librosa.stft(s, n_fft=1024, hop_length=512)\n",
    "        S_abs = np.abs(S).T\n",
    "        recover_S = recover_train(S.T, S_abs)\n",
    "        librosa.output.write_wav('{}/tex{:04d}.wav'.format(target_path, i), librosa.istft(recover_S.T, hop_length=512), sr)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(112, 513)\n",
      "(112, 513)\n",
      "(112, 513)\n",
      "(112, 513)\n",
      "(112, 513)\n",
      "(112, 513)\n",
      "(112, 513)\n",
      "(112, 513)\n",
      "(112, 513)\n",
      "(112, 513)\n",
      "(112, 513)\n",
      "(112, 513)\n",
      "(112, 513)\n",
      "(112, 513)\n",
      "(112, 513)\n",
      "(112, 513)\n",
      "(112, 513)\n",
      "(112, 513)\n",
      "(112, 513)\n",
      "(112, 513)\n",
      "(176, 513)\n",
      "(176, 513)\n",
      "(176, 513)\n",
      "(176, 513)\n",
      "(176, 513)\n",
      "(176, 513)\n",
      "(176, 513)\n",
      "(176, 513)\n",
      "(176, 513)\n",
      "(176, 513)\n",
      "(168, 513)\n",
      "(168, 513)\n",
      "(168, 513)\n",
      "(168, 513)\n",
      "(168, 513)\n",
      "(168, 513)\n",
      "(168, 513)\n",
      "(168, 513)\n",
      "(168, 513)\n",
      "(168, 513)\n",
      "(112, 513)\n",
      "(112, 513)\n",
      "(112, 513)\n",
      "(112, 513)\n",
      "(112, 513)\n",
      "(112, 513)\n",
      "(112, 513)\n",
      "(112, 513)\n",
      "(112, 513)\n",
      "(112, 513)\n",
      "(120, 513)\n",
      "(120, 513)\n",
      "(120, 513)\n",
      "(120, 513)\n",
      "(120, 513)\n",
      "(120, 513)\n",
      "(120, 513)\n",
      "(120, 513)\n",
      "(120, 513)\n",
      "(120, 513)\n",
      "(152, 513)\n",
      "(152, 513)\n",
      "(152, 513)\n",
      "(152, 513)\n",
      "(152, 513)\n",
      "(152, 513)\n",
      "(152, 513)\n",
      "(152, 513)\n",
      "(152, 513)\n",
      "(152, 513)\n",
      "(144, 513)\n",
      "(144, 513)\n",
      "(144, 513)\n",
      "(144, 513)\n",
      "(144, 513)\n",
      "(144, 513)\n",
      "(144, 513)\n",
      "(144, 513)\n",
      "(144, 513)\n",
      "(144, 513)\n",
      "(104, 513)\n",
      "(104, 513)\n",
      "(104, 513)\n",
      "(104, 513)\n",
      "(104, 513)\n",
      "(104, 513)\n",
      "(104, 513)\n",
      "(104, 513)\n",
      "(104, 513)\n",
      "(104, 513)\n",
      "(104, 513)\n",
      "(104, 513)\n",
      "(104, 513)\n",
      "(104, 513)\n",
      "(104, 513)\n",
      "(104, 513)\n",
      "(104, 513)\n",
      "(104, 513)\n",
      "(104, 513)\n",
      "(104, 513)\n",
      "(112, 513)\n",
      "(112, 513)\n",
      "(112, 513)\n",
      "(112, 513)\n",
      "(112, 513)\n",
      "(112, 513)\n",
      "(112, 513)\n",
      "(112, 513)\n",
      "(112, 513)\n",
      "(112, 513)\n",
      "(120, 513)\n",
      "(120, 513)\n",
      "(120, 513)\n",
      "(120, 513)\n",
      "(120, 513)\n",
      "(120, 513)\n",
      "(120, 513)\n",
      "(120, 513)\n",
      "(120, 513)\n",
      "(120, 513)\n",
      "(112, 513)\n",
      "(112, 513)\n",
      "(112, 513)\n",
      "(112, 513)\n",
      "(112, 513)\n",
      "(112, 513)\n",
      "(112, 513)\n",
      "(112, 513)\n",
      "(112, 513)\n",
      "(112, 513)\n",
      "(80, 513)\n",
      "(80, 513)\n",
      "(80, 513)\n",
      "(80, 513)\n",
      "(80, 513)\n",
      "(80, 513)\n",
      "(80, 513)\n",
      "(80, 513)\n",
      "(80, 513)\n",
      "(80, 513)\n",
      "(120, 513)\n",
      "(120, 513)\n",
      "(120, 513)\n",
      "(120, 513)\n",
      "(120, 513)\n",
      "(120, 513)\n",
      "(120, 513)\n",
      "(120, 513)\n",
      "(120, 513)\n",
      "(120, 513)\n",
      "(88, 513)\n",
      "(88, 513)\n",
      "(88, 513)\n",
      "(88, 513)\n",
      "(88, 513)\n",
      "(88, 513)\n",
      "(88, 513)\n",
      "(88, 513)\n",
      "(88, 513)\n",
      "(88, 513)\n",
      "(96, 513)\n",
      "(96, 513)\n",
      "(96, 513)\n",
      "(96, 513)\n",
      "(96, 513)\n",
      "(96, 513)\n",
      "(96, 513)\n",
      "(96, 513)\n",
      "(96, 513)\n",
      "(96, 513)\n",
      "(64, 513)\n",
      "(64, 513)\n",
      "(64, 513)\n",
      "(64, 513)\n",
      "(64, 513)\n",
      "(64, 513)\n",
      "(64, 513)\n",
      "(64, 513)\n",
      "(64, 513)\n",
      "(64, 513)\n",
      "(96, 513)\n",
      "(96, 513)\n",
      "(96, 513)\n",
      "(96, 513)\n",
      "(96, 513)\n",
      "(96, 513)\n",
      "(96, 513)\n",
      "(96, 513)\n",
      "(96, 513)\n",
      "(96, 513)\n",
      "(96, 513)\n",
      "(96, 513)\n",
      "(96, 513)\n",
      "(96, 513)\n",
      "(96, 513)\n",
      "(96, 513)\n",
      "(96, 513)\n",
      "(96, 513)\n",
      "(96, 513)\n",
      "(96, 513)\n",
      "(104, 513)\n",
      "(104, 513)\n",
      "(104, 513)\n",
      "(104, 513)\n",
      "(104, 513)\n",
      "(104, 513)\n",
      "(104, 513)\n",
      "(104, 513)\n",
      "(104, 513)\n",
      "(104, 513)\n",
      "(80, 513)\n",
      "(80, 513)\n",
      "(80, 513)\n",
      "(80, 513)\n",
      "(80, 513)\n",
      "(80, 513)\n",
      "(80, 513)\n",
      "(80, 513)\n",
      "(80, 513)\n",
      "(80, 513)\n",
      "(128, 513)\n",
      "(128, 513)\n",
      "(128, 513)\n",
      "(128, 513)\n",
      "(128, 513)\n",
      "(128, 513)\n",
      "(128, 513)\n",
      "(128, 513)\n",
      "(128, 513)\n",
      "(128, 513)\n",
      "(200, 513)\n",
      "(200, 513)\n",
      "(200, 513)\n",
      "(200, 513)\n",
      "(200, 513)\n",
      "(200, 513)\n",
      "(200, 513)\n",
      "(200, 513)\n",
      "(200, 513)\n",
      "(200, 513)\n",
      "(104, 513)\n",
      "(104, 513)\n",
      "(104, 513)\n",
      "(104, 513)\n",
      "(104, 513)\n",
      "(104, 513)\n",
      "(104, 513)\n",
      "(104, 513)\n",
      "(104, 513)\n",
      "(104, 513)\n",
      "(88, 513)\n",
      "(88, 513)\n",
      "(88, 513)\n",
      "(88, 513)\n",
      "(88, 513)\n",
      "(88, 513)\n",
      "(88, 513)\n",
      "(88, 513)\n",
      "(88, 513)\n",
      "(88, 513)\n",
      "(80, 513)\n",
      "(80, 513)\n",
      "(80, 513)\n",
      "(80, 513)\n",
      "(80, 513)\n",
      "(80, 513)\n",
      "(80, 513)\n",
      "(80, 513)\n",
      "(80, 513)\n",
      "(80, 513)\n",
      "(104, 513)\n",
      "(104, 513)\n",
      "(104, 513)\n",
      "(104, 513)\n",
      "(104, 513)\n",
      "(104, 513)\n",
      "(104, 513)\n",
      "(104, 513)\n",
      "(104, 513)\n",
      "(104, 513)\n",
      "(88, 513)\n",
      "(88, 513)\n",
      "(88, 513)\n",
      "(88, 513)\n",
      "(88, 513)\n",
      "(88, 513)\n",
      "(88, 513)\n",
      "(88, 513)\n",
      "(88, 513)\n",
      "(88, 513)\n",
      "(88, 513)\n",
      "(88, 513)\n",
      "(88, 513)\n",
      "(88, 513)\n",
      "(88, 513)\n",
      "(88, 513)\n",
      "(88, 513)\n",
      "(88, 513)\n",
      "(88, 513)\n",
      "(88, 513)\n",
      "(144, 513)\n",
      "(144, 513)\n",
      "(144, 513)\n",
      "(144, 513)\n",
      "(144, 513)\n",
      "(144, 513)\n",
      "(144, 513)\n",
      "(144, 513)\n",
      "(144, 513)\n",
      "(144, 513)\n",
      "(144, 513)\n",
      "(144, 513)\n",
      "(144, 513)\n",
      "(144, 513)\n",
      "(144, 513)\n",
      "(144, 513)\n",
      "(144, 513)\n",
      "(144, 513)\n",
      "(144, 513)\n",
      "(144, 513)\n",
      "(168, 513)\n",
      "(168, 513)\n",
      "(168, 513)\n",
      "(168, 513)\n",
      "(168, 513)\n",
      "(168, 513)\n",
      "(168, 513)\n",
      "(168, 513)\n",
      "(168, 513)\n",
      "(168, 513)\n",
      "(120, 513)\n",
      "(120, 513)\n",
      "(120, 513)\n",
      "(120, 513)\n",
      "(120, 513)\n",
      "(120, 513)\n",
      "(120, 513)\n",
      "(120, 513)\n",
      "(120, 513)\n",
      "(120, 513)\n",
      "(56, 513)\n",
      "(56, 513)\n",
      "(56, 513)\n",
      "(56, 513)\n",
      "(56, 513)\n",
      "(56, 513)\n",
      "(56, 513)\n",
      "(56, 513)\n",
      "(56, 513)\n",
      "(56, 513)\n",
      "(120, 513)\n",
      "(120, 513)\n",
      "(120, 513)\n",
      "(120, 513)\n",
      "(120, 513)\n",
      "(120, 513)\n",
      "(120, 513)\n",
      "(120, 513)\n",
      "(120, 513)\n",
      "(120, 513)\n",
      "(88, 513)\n",
      "(88, 513)\n",
      "(88, 513)\n",
      "(88, 513)\n",
      "(88, 513)\n",
      "(88, 513)\n",
      "(88, 513)\n",
      "(88, 513)\n",
      "(88, 513)\n",
      "(88, 513)\n",
      "(160, 513)\n",
      "(160, 513)\n",
      "(160, 513)\n",
      "(160, 513)\n",
      "(160, 513)\n",
      "(160, 513)\n",
      "(160, 513)\n",
      "(160, 513)\n",
      "(160, 513)\n",
      "(160, 513)\n",
      "(72, 513)\n",
      "(72, 513)\n",
      "(72, 513)\n",
      "(72, 513)\n",
      "(72, 513)\n",
      "(72, 513)\n",
      "(72, 513)\n",
      "(72, 513)\n",
      "(72, 513)\n",
      "(72, 513)\n",
      "(112, 513)\n",
      "(112, 513)\n",
      "(112, 513)\n",
      "(112, 513)\n",
      "(112, 513)\n",
      "(112, 513)\n",
      "(112, 513)\n",
      "(112, 513)\n",
      "(112, 513)\n",
      "(112, 513)\n"
     ]
    }
   ],
   "source": [
    "recover_test_data('timit-homework/te', './result_te', 400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
