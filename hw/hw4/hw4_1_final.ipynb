{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZFO8YAICVAO3"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import math\n",
    "import pickle\n",
    "import librosa\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 91,
     "resources": {
      "http://localhost:8080/nbextensions/google.colab/files.js": {
       "data": "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",
       "headers": [
        [
         "content-type",
         "application/javascript"
        ]
       ],
       "ok": true,
       "status": 200,
       "status_text": ""
      }
     }
    },
    "colab_type": "code",
    "id": "joynBpTSVDQ-",
    "outputId": "6a77a17a-b69b-43d2-e3a4-f25ad0223dc5"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "     <input type=\"file\" id=\"files-bb43fdb2-1332-4f17-9c89-4ab82c6e0c31\" name=\"files[]\" multiple disabled />\n",
       "     <output id=\"result-bb43fdb2-1332-4f17-9c89-4ab82c6e0c31\">\n",
       "      Upload widget is only available when the cell has been executed in the\n",
       "      current browser session. Please rerun this cell to enable.\n",
       "      </output>\n",
       "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "     <input type=\"file\" id=\"files-c97bd191-be04-49d2-838d-529d3da9b432\" name=\"files[]\" multiple disabled />\n",
       "     <output id=\"result-c97bd191-be04-49d2-838d-529d3da9b432\">\n",
       "      Upload widget is only available when the cell has been executed in the\n",
       "      current browser session. Please rerun this cell to enable.\n",
       "      </output>\n",
       "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving hw4_tes.pkl to hw4_tes.pkl\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# In Google Colaborary\n",
    "from google.colab import files\n",
    "hw4_trs = files.upload() # train_clean_male.wav\n",
    "hw4_tes = files.upload() # train_clean_male.wav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XFJgK3VsVZQd"
   },
   "outputs": [],
   "source": [
    "# Load data\n",
    "with open('hw4_trs.pkl', 'rb') as f:\n",
    "    train_data_raw = pickle.load(f)\n",
    "\n",
    "with open('hw4_tes.pkl', 'rb') as f:\n",
    "    test_data_raw = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "l2T1P4R3Wly5",
    "outputId": "2e73f788-a65a-4168-ef9c-c3fd28092455"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500, 16180)\n",
      "(200, 22631)\n"
     ]
    }
   ],
   "source": [
    "print(train_data_raw.shape)\n",
    "print(test_data_raw.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1s9G2nDIWmVH"
   },
   "outputs": [],
   "source": [
    "train_data_input = np.array([np.abs(librosa.stft(row, n_fft=1024, hop_length=512)) for row in train_data_raw])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "trW1nW56Wor_"
   },
   "outputs": [],
   "source": [
    "# turncate test_data\n",
    "test_data_input = np.array([np.abs(librosa.stft(row, n_fft=1024, hop_length=512)) for row in test_data_raw[:,0:16180]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "x0GtQTPjWrMp",
    "outputId": "78a86705-5ecf-48f9-dc67-1a6a9501fc49"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500, 513, 32)\n",
      "(200, 513, 32)\n"
     ]
    }
   ],
   "source": [
    "print(train_data_input.shape)\n",
    "print(test_data_input.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "N-mzFijHWvV1"
   },
   "outputs": [],
   "source": [
    "def generate_pair(data_size):\n",
    "    # get positive pair\n",
    "    positive_pair = np.zeros((0, 2), dtype=int)\n",
    "    for i in range(0, data_size, 10):\n",
    "        for j in range(i, i+10):\n",
    "            for k in range(j+1, i+10):\n",
    "                positive_pair = np.vstack((positive_pair, np.array([j, k], dtype=int)))\n",
    "    \n",
    "    # get negative pair\n",
    "    negative_pair = np.zeros((0, 2), dtype=int)\n",
    "    for i in range(0, data_size, 10):\n",
    "        current = list(range(i, i+10))\n",
    "        others = [ x for x in list(range(data_size)) if x not in current ]\n",
    "        # generate 45 negative sample per speaker\n",
    "        for j in range(45):\n",
    "            p1 = np.random.choice(current)\n",
    "            p2 = np.random.choice(others)        \n",
    "            negative_pair = np.vstack((negative_pair, np.array([p1, p2], dtype=int)))\n",
    "    return np.concatenate((negative_pair, positive_pair))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "A1i4zWClW0AU",
    "outputId": "8c66097a-4151-4611-f139-a440f4a63a53"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4500, 2) (1800, 2)\n"
     ]
    }
   ],
   "source": [
    "train_pair = generate_pair(500)\n",
    "test_pair = generate_pair(200)\n",
    "print(train_pair.shape, test_pair.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jDfpnaDLW0lh"
   },
   "outputs": [],
   "source": [
    "def generate_label(n):\n",
    "    # build data label\n",
    "    negative_label = np.zeros(45*n)\n",
    "    positive_label = np.ones(45*n)\n",
    "    return np.concatenate((negative_label, positive_label))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "fEJrsOplW4Ua",
    "outputId": "a4b099ec-fcf2-4b81-8f40-abce82091379"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4500,) (1800,)\n"
     ]
    }
   ],
   "source": [
    "train_label = generate_label(50)\n",
    "test_label = generate_label(20)\n",
    "print(train_label.shape, test_label.shape)\n",
    "# print(test_label[890:920])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "25bNGfPbW6rG"
   },
   "outputs": [],
   "source": [
    "# Training Parameters\n",
    "learning_rate = 0.0001\n",
    "batch_size = 128\n",
    "\n",
    "# Hyper Parameter\n",
    "num_input =  513*32 # \n",
    "num_hidden = 1024  # hidden layer num of features\n",
    "num_feature = 512\n",
    "\n",
    "drop_rate = 0.3\n",
    "is_training = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "aqO1FqsdYPBq",
    "outputId": "5eec6a43-5f84-4601-ccfb-140dc37dcec3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1800, 16416) (1800,)\n"
     ]
    }
   ],
   "source": [
    "# create test data pair\n",
    "test_input_x1 = np.array([test_data_input[x[0]] for x in test_pair]).reshape(-1, num_input)\n",
    "test_input_x2 = np.array([test_data_input[x[1]] for x in test_pair]).reshape(-1, num_input)\n",
    "test_input_y = test_label\n",
    "\n",
    "print(test_input_x1.shape, test_input_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WF2I8g6CYdg3"
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "# Create batch data for training\n",
    "train_data = tf.data.Dataset.from_tensor_slices(tf.constant(train_pair))\n",
    "label_data = tf.data.Dataset.from_tensor_slices(tf.constant(train_label))\n",
    "batch_data = tf.data.Dataset.zip((train_data, label_data)).shuffle(10**7, reshuffle_each_iteration=True)\n",
    "batch_data = batch_data.repeat().batch(batch_size)\n",
    "\n",
    "iterator = batch_data.make_one_shot_iterator()\n",
    "next_batch = iterator.get_next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HLG4SBfSYf7r"
   },
   "outputs": [],
   "source": [
    "with tf.variable_scope(\"nn\", reuse=tf.AUTO_REUSE):\n",
    "    X1 = tf.placeholder(\"float\", [None, num_input])\n",
    "    X2 = tf.placeholder(\"float\", [None, num_input])\n",
    "    Y = tf.placeholder(\"float\", [None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "ofuUITnNYiV2",
    "outputId": "1f3ff6f8-8fdc-43dd-f925-311cb6165ca4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 512)\n",
      "(?, 512)\n",
      "(?, 1) (?,) (?,)\n"
     ]
    }
   ],
   "source": [
    "with tf.variable_scope(\"nn\", reuse=tf.AUTO_REUSE):\n",
    "    initializer = tf.contrib.layers.variance_scaling_initializer()\n",
    "    \n",
    "    \n",
    "    d1 = tf.layers.dense(X1, units=num_hidden, name=\"d1\", activation=tf.nn.relu, kernel_initializer=initializer)\n",
    "    dropout1 = tf.layers.dropout(d1, rate=drop_rate, training=is_training, name=\"dropout1\")\n",
    "    ln1 = tf.contrib.layers.layer_norm(dropout1, scope=\"ln1\")    \n",
    "    d2 = tf.layers.dense(ln1, units=num_hidden/2, name=\"d2\", activation=tf.nn.relu, kernel_initializer=initializer)\n",
    "    dropout2 = tf.layers.dropout(d2, rate=drop_rate, training=is_training, name=\"dropout2\")\n",
    "    ln2 = tf.contrib.layers.layer_norm(dropout2, scope=\"ln2\")\n",
    "    d3 = tf.layers.dense(ln2, units=num_hidden/4, name=\"d3\", activation=tf.nn.relu, kernel_initializer=initializer)\n",
    "    dropout3 = tf.layers.dropout(d3, rate=drop_rate, training=is_training, name=\"dropout3\")\n",
    "    ln3 = tf.contrib.layers.layer_norm(dropout3, scope=\"ln3\")    \n",
    "    d4 = tf.layers.dense(ln3, units=num_hidden/2, name=\"d4\", activation=tf.nn.relu, kernel_initializer=initializer)    \n",
    "    dropout4 = tf.layers.dropout(d4, rate=drop_rate, training=is_training, name=\"dropout4\")\n",
    "    ln4 = tf.contrib.layers.layer_norm(dropout4, scope=\"ln4\")\n",
    "    Y1 = tf.layers.dense(ln4, units=num_feature, name=\"d5\", kernel_initializer=initializer)\n",
    "\n",
    "    d1 = tf.layers.dense(X2, units=num_hidden, reuse=True, name=\"d1\", activation=tf.nn.relu, kernel_initializer=initializer)\n",
    "    dropout1 = tf.layers.dropout(d1, rate=drop_rate, training=is_training, name=\"dropout1\")\n",
    "    ln1 = tf.contrib.layers.layer_norm(dropout1, reuse=True, scope=\"ln1\")    \n",
    "    d2 = tf.layers.dense(ln1, units=num_hidden/2, reuse=True, name=\"d2\", activation=tf.nn.relu, kernel_initializer=initializer)\n",
    "    dropout2 = tf.layers.dropout(d2, rate=drop_rate, training=is_training, name=\"dropout2\")\n",
    "    ln2 = tf.contrib.layers.layer_norm(dropout2, reuse=True, scope=\"ln2\")\n",
    "    d3 = tf.layers.dense(ln2, units=num_hidden/4, reuse=True, name=\"d3\", activation=tf.nn.relu, kernel_initializer=initializer)\n",
    "    dropout3 = tf.layers.dropout(d3, rate=drop_rate, training=is_training, name=\"dropout3\")\n",
    "    ln3 = tf.contrib.layers.layer_norm(dropout3, reuse=True, scope=\"ln3\")\n",
    "    d4 = tf.layers.dense(ln3, units=num_hidden/2, reuse=True, name=\"d4\", activation=tf.nn.relu, kernel_initializer=initializer)    \n",
    "    dropout4 = tf.layers.dropout(d4, rate=drop_rate, training=is_training, name=\"dropout4\")\n",
    "    ln4 = tf.contrib.layers.layer_norm(dropout4, reuse=True, scope=\"ln4\")\n",
    "    Y2 = tf.layers.dense(ln4, units=num_feature, reuse=True, name=\"d5\", kernel_initializer=initializer)\n",
    "\n",
    "    print(Y1.shape)\n",
    "    print(Y2.shape)\n",
    "    Y1_Y2_product = tf.reduce_sum(tf.multiply( Y1, Y2 ), 1, keepdims=True)\n",
    "    Y_pred = tf.reshape(tf.sigmoid(Y1_Y2_product), [-1])\n",
    "    print(Y1_Y2_product.shape, Y_pred.shape, Y.shape)\n",
    "\n",
    "    loss = tf.reduce_mean( -Y*tf.log(Y_pred + 10e-6) - (1 - Y) * tf.log(1 - Y_pred + 10e-6))\n",
    "\n",
    "    correct_prediction = tf.equal(tf.round(Y_pred), Y)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    train_op = tf.train.AdamOptimizer(learning_rate).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9JJoWZUgYln4"
   },
   "outputs": [],
   "source": [
    "# Initial session\n",
    "sess=tf.Session()\n",
    "tf.global_variables_initializer().run(session=sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 714
    },
    "colab_type": "code",
    "id": "Cwiroyd1YrP3",
    "outputId": "825077e8-2afe-4c6f-93e5-e9ed436375fc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step:0 Train Loss = 0.26982442 Train Accuracy = 0.9765625 Test Accuracy = 0.6072222\n",
      "Training Step:1000 Train Loss = 0.44971403 Train Accuracy = 0.9609375 Test Accuracy = 0.60333335\n",
      "Training Step:2000 Train Loss = 0.1798796 Train Accuracy = 0.984375 Test Accuracy = 0.5833333\n",
      "Training Step:3000 Train Loss = 0.89943814 Train Accuracy = 0.921875 Test Accuracy = 0.615\n",
      "Training Step:4000 Train Loss = 0.8094933 Train Accuracy = 0.9296875 Test Accuracy = 0.62277776\n",
      "Training Step:5000 Train Loss = 0.35976923 Train Accuracy = 0.96875 Test Accuracy = 0.6333333\n",
      "Training Step:6000 Train Loss = 0.6296036 Train Accuracy = 0.9453125 Test Accuracy = 0.6155556\n",
      "Training Step:7000 Train Loss = 1.0793277 Train Accuracy = 0.90625 Test Accuracy = 0.5961111\n",
      "Training Step:8000 Train Loss = 0.44971403 Train Accuracy = 0.9609375 Test Accuracy = 0.6022222\n",
      "Training Step:9000 Train Loss = 0.44971403 Train Accuracy = 0.9609375 Test Accuracy = 0.60555553\n",
      "Training Step:10000 Train Loss = 0.44971403 Train Accuracy = 0.9609375 Test Accuracy = 0.6333333\n",
      "Training Step:11000 Train Loss = 0.44971403 Train Accuracy = 0.9609375 Test Accuracy = 0.61333334\n",
      "Training Step:12000 Train Loss = 0.44971403 Train Accuracy = 0.9609375 Test Accuracy = 0.5888889\n",
      "Training Step:13000 Train Loss = 0.9893829 Train Accuracy = 0.9140625 Test Accuracy = 0.59944445\n",
      "Training Step:14000 Train Loss = 0.89943814 Train Accuracy = 0.921875 Test Accuracy = 0.60055554\n",
      "Training Step:15000 Train Loss = 0.8094933 Train Accuracy = 0.9296875 Test Accuracy = 0.5933333\n",
      "Training Step:16000 Train Loss = 0.44971403 Train Accuracy = 0.9609375 Test Accuracy = 0.595\n",
      "Training Step:17000 Train Loss = 0.35976923 Train Accuracy = 0.96875 Test Accuracy = 0.5911111\n",
      "Training Step:18000 Train Loss = 0.53965884 Train Accuracy = 0.953125 Test Accuracy = 0.6166667\n",
      "Training Step:19000 Train Loss = 0.80949324 Train Accuracy = 0.9296875 Test Accuracy = 0.60388887\n",
      "Training Step:20000 Train Loss = 0.71954846 Train Accuracy = 0.9375 Test Accuracy = 0.6155556\n",
      "Training Step:21000 Train Loss = 0.44971403 Train Accuracy = 0.9609375 Test Accuracy = 0.5922222\n",
      "Training Step:22000 Train Loss = 0.5602931 Train Accuracy = 0.9453125 Test Accuracy = 0.60055554\n",
      "Training Step:23000 Train Loss = 0.53965884 Train Accuracy = 0.953125 Test Accuracy = 0.605\n",
      "Training Step:24000 Train Loss = 0.35976923 Train Accuracy = 0.96875 Test Accuracy = 0.615\n",
      "Training Step:25000 Train Loss = 0.8997355 Train Accuracy = 0.921875 Test Accuracy = 0.61277777\n",
      "Training Step:26000 Train Loss = 0.6296036 Train Accuracy = 0.9453125 Test Accuracy = 0.605\n",
      "Training Step:27000 Train Loss = 0.71954846 Train Accuracy = 0.9375 Test Accuracy = 0.6016667\n",
      "Training Step:28000 Train Loss = 0.53965884 Train Accuracy = 0.953125 Test Accuracy = 0.57055557\n",
      "Training Step:29000 Train Loss = 0.899438 Train Accuracy = 0.921875 Test Accuracy = 0.60333335\n",
      "Training Step:30000 Train Loss = 0.53965884 Train Accuracy = 0.953125 Test Accuracy = 0.62166667\n",
      "Training Step:31000 Train Loss = 0.80949324 Train Accuracy = 0.9296875 Test Accuracy = 0.5927778\n",
      "Training Step:32000 Train Loss = 0.35976923 Train Accuracy = 0.96875 Test Accuracy = 0.61\n",
      "Training Step:33000 Train Loss = 0.6296036 Train Accuracy = 0.9453125 Test Accuracy = 0.5827778\n",
      "Training Step:34000 Train Loss = 0.44971403 Train Accuracy = 0.9609375 Test Accuracy = 0.6016667\n",
      "Training Step:35000 Train Loss = 0.35976923 Train Accuracy = 0.96875 Test Accuracy = 0.62277776\n",
      "Training Step:36000 Train Loss = 0.53965884 Train Accuracy = 0.953125 Test Accuracy = 0.5972222\n",
      "Training Step:37000 Train Loss = 0.53965884 Train Accuracy = 0.953125 Test Accuracy = 0.5927778\n",
      "Training Step:38000 Train Loss = 0.44971403 Train Accuracy = 0.9609375 Test Accuracy = 0.605\n",
      "Training Step:39000 Train Loss = 0.6296036 Train Accuracy = 0.9453125 Test Accuracy = 0.6066667\n",
      "Training Step:40000 Train Loss = 0.44971403 Train Accuracy = 0.9609375 Test Accuracy = 0.58944446\n"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "training_steps = 40000\n",
    "for i in range(training_steps+1):\n",
    "    (batch_x, batch_y) = sess.run(next_batch)\n",
    "    # print(batch_x, batch_y)\n",
    "    input_x1 = np.array([train_data_input[x[0]] for x in batch_x]).reshape(-1, num_input)\n",
    "    input_x2 = np.array([train_data_input[x[1]] for x in batch_x]).reshape(-1, num_input)\n",
    "    input_y = batch_y\n",
    "    _, loss_value, acc_value = sess.run((train_op, loss, accuracy), feed_dict={X1: input_x1, X2: input_x2, Y: input_y})\n",
    "    if i % 1000 == 0:\n",
    "        is_training = False\n",
    "        print('Training Step:' + str(i) + ' Train Loss = ' + str(loss_value) + \n",
    "              ' Train Accuracy = ' + str(acc_value) +              \n",
    "              ' Test Accuracy = ' + str(sess.run(accuracy, feed_dict={X1: test_input_x1, X2: test_input_x2, Y: test_input_y})))\n",
    "        is_training = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "X6zH900sZmyY"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "hw4.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
