{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(55000, 784) (5000, 784) (10000, 784)\n",
      "(55000, 10) (5000, 10) (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "print(mnist.train.images.shape, mnist.validation.images.shape, mnist.test.images.shape)\n",
    "print(mnist.train.labels.shape, mnist.validation.labels.shape, mnist.test.labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def TRAIN_SIZE(num):\n",
    "#     print ('Total Training Images in Dataset = ' + str(mnist.train.images.shape))\n",
    "#     print ('--------------------------------------------------')\n",
    "#     x_train = mnist.train.images[:num,:]\n",
    "#     print ('x_train Examples Loaded = ' + str(x_train.shape))\n",
    "#     y_train = mnist.train.labels[:num,:]\n",
    "#     print ('y_train Examples Loaded = ' + str(y_train.shape))\n",
    "#     print('')\n",
    "#     return x_train, y_train\n",
    "\n",
    "# def TEST_SIZE(num):\n",
    "#     print ('Total Test Examples in Dataset = ' + str(mnist.test.images.shape))\n",
    "#     print ('--------------------------------------------------')\n",
    "#     x_test = mnist.test.images[:num,:]\n",
    "#     print ('x_test Examples Loaded = ' + str(x_test.shape))\n",
    "#     y_test = mnist.test.labels[:num,:]\n",
    "#     print ('y_test Examples Loaded = ' + str(y_test.shape))\n",
    "#     return x_test, y_test\n",
    "\n",
    "def display_digit(x_train, y_train, num):\n",
    "    label = y_train[num].argmax(axis=0)\n",
    "    image = x_train[num].reshape([28,28])\n",
    "    plt.title('Example: %d  Label: %d' % (num, label))\n",
    "    plt.imshow(image, cmap=plt.get_cmap('gray_r'))\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "LEARNING_RATE = 1e-1\n",
    "TRAIN_STEPS = 2000\n",
    "\n",
    "\n",
    "x = tf.placeholder(tf.float32, [None, 784])\n",
    "y_ = tf.placeholder(tf.float32, [None, 10])\n",
    "\n",
    "l1 = tf.layers.dense(x, units=50)\n",
    "l2 = tf.layers.dense(l1, units=50)\n",
    "l3 = tf.layers.dense(l2, units=10)\n",
    "\n",
    "y = tf.nn.softmax(l3)\n",
    "\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# loss = tf.losses.mean_squared_error(labels=y_, predictions=y)\n",
    "# loss = tf.reduce_mean(-tf.reduce_sum(y_ * tf.log(y), reduction_indices=[1]))\n",
    "\n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(labels=y_, logits=y))\n",
    "train_step = tf.train.GradientDescentOptimizer(LEARNING_RATE).minimize(loss)\n",
    "\n",
    "\n",
    "correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(y_, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step:0  Accuracy =  0.0993  Loss =  2.292798\n",
      "Training Step:100  Accuracy =  0.5438  Loss =  1.9359577\n",
      "Training Step:200  Accuracy =  0.7776  Loss =  1.7227684\n",
      "Training Step:300  Accuracy =  0.8506  Loss =  1.6442333\n",
      "Training Step:400  Accuracy =  0.8777  Loss =  1.6476767\n",
      "Training Step:500  Accuracy =  0.8902  Loss =  1.5393214\n",
      "Training Step:600  Accuracy =  0.8932  Loss =  1.5884681\n",
      "Training Step:700  Accuracy =  0.8948  Loss =  1.668231\n",
      "Training Step:800  Accuracy =  0.903  Loss =  1.5665848\n",
      "Training Step:900  Accuracy =  0.9036  Loss =  1.5489458\n",
      "Training Step:1000  Accuracy =  0.9072  Loss =  1.5956498\n",
      "Training Step:1100  Accuracy =  0.9076  Loss =  1.5242199\n",
      "Training Step:1200  Accuracy =  0.9118  Loss =  1.5531056\n",
      "Training Step:1300  Accuracy =  0.9109  Loss =  1.6068088\n",
      "Training Step:1400  Accuracy =  0.9113  Loss =  1.5389365\n",
      "Training Step:1500  Accuracy =  0.9115  Loss =  1.5697154\n",
      "Training Step:1600  Accuracy =  0.9114  Loss =  1.5231334\n",
      "Training Step:1700  Accuracy =  0.9131  Loss =  1.5109885\n",
      "Training Step:1800  Accuracy =  0.9148  Loss =  1.5380441\n",
      "Training Step:1900  Accuracy =  0.915  Loss =  1.5691915\n",
      "Training Step:2000  Accuracy =  0.9176  Loss =  1.5699023\n"
     ]
    }
   ],
   "source": [
    "for i in range(TRAIN_STEPS+1):\n",
    "    batch = mnist.train.next_batch(50)\n",
    "    _, loss_value = sess.run((train_step, loss), feed_dict={x: batch[0], y_: batch[1]})\n",
    "    if i%100 == 0:\n",
    "        print('Training Step:' + str(i) + '  Accuracy =  ' + \n",
    "              str(sess.run(accuracy, feed_dict={x: mnist.test.images, y_: mnist.test.labels})) + \n",
    "              '  Loss =  ' + str(loss_value))\n",
    "                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "\n",
    "s, sr=librosa.load(\"data/train_clean_male.wav\", sr=None)\n",
    "S=librosa.stft(s, n_fft=1024, hop_length=512)\n",
    "sn, sr=librosa.load(\"data/train_dirty_male.wav\", sr=None)\n",
    "X=librosa.stft(sn, n_fft=1024, hop_length=512)\n",
    "# print(S.shape)\n",
    "# print(X.shape)\n",
    "# print(S);\n",
    "# print(np.abs(S));\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/device:CPU:0']\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "def get_available_devices():\n",
    "    local_device_protos = device_lib.list_local_devices()\n",
    "    return [x.name for x in local_device_protos]\n",
    "\n",
    "print(get_available_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
